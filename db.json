{"meta":{"version":1,"warehouse":"3.0.2"},"models":{"Asset":[{"_id":"themes/landscape/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":0,"renderable":1},{"_id":"themes/Minos/source/css/insight.scss","path":"css/insight.scss","modified":0,"renderable":1},{"_id":"themes/Minos/source/images/check.svg","path":"images/check.svg","modified":0,"renderable":1},{"_id":"themes/Minos/source/css/style.scss","path":"css/style.scss","modified":0,"renderable":1},{"_id":"themes/Minos/source/images/exclamation.svg","path":"images/exclamation.svg","modified":0,"renderable":1},{"_id":"themes/Minos/source/images/info.svg","path":"images/info.svg","modified":0,"renderable":1},{"_id":"themes/Minos/source/images/question.svg","path":"images/question.svg","modified":0,"renderable":1},{"_id":"themes/Minos/source/images/logo.png","path":"images/logo.png","modified":0,"renderable":1},{"_id":"themes/Minos/source/images/quote-left.svg","path":"images/quote-left.svg","modified":0,"renderable":1},{"_id":"themes/Minos/source/js/insight.js","path":"js/insight.js","modified":0,"renderable":1},{"_id":"themes/Minos/source/js/script.js","path":"js/script.js","modified":0,"renderable":1}],"Cache":[{"_id":"themes/landscape/.gitignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1589626151237},{"_id":"themes/landscape/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1589626151237},{"_id":"themes/landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1589626151237},{"_id":"themes/landscape/README.md","hash":"37fae88639ef60d63bd0de22314d7cc4c5d94b07","modified":1589626151237},{"_id":"themes/landscape/_config.yml","hash":"79ac6b9ed6a4de5a21ea53fc3f5a3de92e2475ff","modified":1589626151237},{"_id":"themes/landscape/package.json","hash":"544f21a0b2c7034998b36ae94dba6e3e0f39f228","modified":1589626151244},{"_id":"source/_posts/hello-world.md","hash":"7d98d6592de80fdcd2949bd7401cec12afd98cdf","modified":1589625131667},{"_id":"themes/landscape/languages/de.yml","hash":"3ebf0775abbee928c8d7bda943c191d166ded0d3","modified":1589626151237},{"_id":"themes/landscape/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1589626151238},{"_id":"themes/landscape/languages/es.yml","hash":"76edb1171b86532ef12cfd15f5f2c1ac3949f061","modified":1589626151238},{"_id":"themes/landscape/languages/ja.yml","hash":"a73e1b9c80fd6e930e2628b393bfe3fb716a21a9","modified":1589626151238},{"_id":"themes/landscape/languages/fr.yml","hash":"415e1c580ced8e4ce20b3b0aeedc3610341c76fb","modified":1589626151238},{"_id":"themes/landscape/languages/ko.yml","hash":"881d6a0a101706e0452af81c580218e0bfddd9cf","modified":1589626151238},{"_id":"themes/landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1589626151238},{"_id":"themes/landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1589626151238},{"_id":"themes/landscape/languages/pt.yml","hash":"57d07b75d434fbfc33b0ddb543021cb5f53318a8","modified":1589626151238},{"_id":"themes/landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1589626151239},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1589626151239},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1589626151239},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1589626151243},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1589626151243},{"_id":"themes/landscape/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1589626151243},{"_id":"themes/landscape/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1589626151243},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1589626151243},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1589626151243},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1589626151243},{"_id":"themes/landscape/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1589626151244},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"d0d753d39038284d52b10e5075979cc97db9cd20","modified":1589626151239},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1589626151239},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"950ddd91db8718153b329b96dc14439ab8463ba5","modified":1589626151239},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"c4c835615d96a950d51fa2c3b5d64d0596534fed","modified":1589626151239},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"93518893cf91287e797ebac543c560e2a63b8d0e","modified":1589626151240},{"_id":"themes/landscape/layout/_partial/gauges-analytics.ejs","hash":"aad6312ac197d6c5aaf2104ac863d7eba46b772a","modified":1589626151240},{"_id":"themes/landscape/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1589626151240},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"5abf77aec957d9445fc71a8310252f0013c84578","modified":1589626151240},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"7e749050be126eadbc42decfbea75124ae430413","modified":1589626151240},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1589626151240},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1589626151241},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1589626151242},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1589626151242},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1589626151242},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1589626151242},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1589626151243},{"_id":"themes/landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1589626151244},{"_id":"themes/landscape/source/css/_variables.styl","hash":"628e307579ea46b5928424313993f17b8d729e92","modified":1589626151246},{"_id":"themes/landscape/source/css/style.styl","hash":"a70d9c44dac348d742702f6ba87e5bb3084d65db","modified":1589626151253},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1589626151253},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1589626151253},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1589626151253},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1589626151253},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1589626151253},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1589626151253},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1589626151255},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1589626151255},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1589626151255},{"_id":"themes/landscape/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1589626151255},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1589626151241},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1589626151241},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1589626151241},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1589626151241},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1589626151241},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1589626151241},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1589626151244},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"10685f8787a79f79c9a26c2f943253450c498e3e","modified":1589626151244},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1589626151245},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1589626151245},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"85ab11e082f4dd86dde72bed653d57ec5381f30c","modified":1589626151245},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"bf4e7be1968dad495b04e83c95eac14c4d0ad7c0","modified":1589626151245},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1589626151245},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1589626151245},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1589626151245},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1589626151246},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1589626151246},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1589626151246},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1589626151247},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1589626151248},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1589626151250},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1589626151254},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1589626151254},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1589626151254},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1589626151254},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1589626151254},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1589626151254},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1589626151250},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1589626151249},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1589626151252},{"_id":"source/_posts/ls.md","hash":"6dcc1506b9e6e9667f9ceedd46556bae389ba5da","modified":1589626496481},{"_id":"source/_posts/hello.md","hash":"f1c014f3abb2e3203ab4338e8811d1457bd83628","modified":1589631715684},{"_id":"themes/Minos/LICENSE","hash":"ca01a2d52b59346e82f079c593df6cb26dd9a7a5","modified":1589633501129},{"_id":"themes/Minos/.gitignore","hash":"8b02e7219e2dd9b50d198819fd7d8f74ebc9db2a","modified":1589633501129},{"_id":"themes/Minos/README.md","hash":"ba6b4e134d718704cfd030e106bf24d6ef8b496d","modified":1589633501129},{"_id":"themes/Minos/_config.yml.example","hash":"bb4c9460057233749b201382baa799cdbd477d36","modified":1589633501129},{"_id":"themes/Minos/package.json","hash":"f9d450db80149dea6c372990cdf51dfde901e5cc","modified":1589633501137},{"_id":"themes/Minos/package-lock.json","hash":"e1fbecec56fb65379bf651f21fb485376e692b38","modified":1589633501137},{"_id":"themes/Minos/languages/de.yml","hash":"3d6abea8c2990b04fcd54ffd88ab15356b5171e8","modified":1589633501129},{"_id":"themes/Minos/languages/es.yml","hash":"5c35950221411e34e7a9821d0b0671da9a458d8c","modified":1589633501130},{"_id":"themes/Minos/languages/en.yml","hash":"ef98c8674fed78f2350598ee8b15fcd53fbd2ae5","modified":1589633501129},{"_id":"themes/Minos/languages/fr.yml","hash":"cca90260b00842bf73fadb3154c2969102cf80c0","modified":1589633501130},{"_id":"themes/Minos/languages/ko.yml","hash":"1acf3f959f1d2b4f7a77e7e82851821aa8635362","modified":1589633501130},{"_id":"themes/Minos/languages/pl.yml","hash":"0ff13d2d14d1f63341cbe576070f724747238dee","modified":1589633501130},{"_id":"themes/Minos/languages/ru.yml","hash":"8e5a58176bf943432ba6e4f1981d9b98fdea36a4","modified":1589633501130},{"_id":"themes/Minos/lib/i18n.js","hash":"4c90aa27420e0e2ff74f80e976fe146e96354f61","modified":1589633501136},{"_id":"themes/Minos/languages/zh-cn.yml","hash":"9c5a489b11a056d1ea7b9d4a0e127aef9e192ee4","modified":1589633501130},{"_id":"themes/Minos/lib/rfc5646.js","hash":"8ecf38d0ec7145720ea8e888da314131712770e8","modified":1589633501137},{"_id":"themes/Minos/languages/zh-tw.yml","hash":"f61b67b9c454d16bc3973f6cb142b98a4e19f9b0","modified":1589633501130},{"_id":"themes/Minos/layout/categories.ejs","hash":"fff6f911d0f548ee749292bc1942f8fbbb1fbfe7","modified":1589633501131},{"_id":"themes/Minos/layout/archive.ejs","hash":"e3eefe819d61b4d0ee069bb705a9f5707a8bf3da","modified":1589633501131},{"_id":"themes/Minos/layout/category.ejs","hash":"403c646878834964883ac41e63952f7b1595c0ba","modified":1589633501131},{"_id":"themes/Minos/layout/index.ejs","hash":"dff9e199d394f82c5416b814f9e644edbe4090f0","modified":1589633501134},{"_id":"themes/Minos/layout/layout.ejs","hash":"45588aa46857cf9403fa79d738ab37a46ddcf773","modified":1589633501134},{"_id":"themes/Minos/layout/post.ejs","hash":"68b84a717efc5ca59ee9eb6202ccf05c5a8abda5","modified":1589633501135},{"_id":"themes/Minos/layout/tags.ejs","hash":"e4a9909119294f131a45f10b2cb1058af5fb9be1","modified":1589633501136},{"_id":"themes/Minos/layout/tag.ejs","hash":"5593c7cf9618ef5650c779ed9d75424f057aa210","modified":1589633501136},{"_id":"themes/Minos/scripts/01_check.js","hash":"e53508ef82a1518ed7e663ce2d87544c20a50779","modified":1589633501137},{"_id":"themes/Minos/scripts/10_i18n.js","hash":"9c1f9e3ec3c6299fc599769783925d1898a632f0","modified":1589633501137},{"_id":"themes/Minos/scripts/99_config.js","hash":"d41a5df0a442728fbc66514476fe043e416d7438","modified":1589633501138},{"_id":"themes/Minos/scripts/99_content.js","hash":"ff61d3d631b06024509d4fe28b4e31590a02f05b","modified":1589633501138},{"_id":"themes/Minos/scripts/99_tags.js","hash":"f97c2332a7e13fed99672b27c4380a6183d8600e","modified":1589633501138},{"_id":"themes/Minos/layout/comment/changyan.ejs","hash":"9ccc7ec354b968e60bdcfcd1dba451d38de61f12","modified":1589633501131},{"_id":"themes/Minos/layout/comment/disqus.ejs","hash":"a2becdc02214a673c804af93488489807fa2c99c","modified":1589633501131},{"_id":"themes/Minos/layout/comment/facebook.ejs","hash":"e73b6f93d98b27ba9068c1685874ecccfbac737b","modified":1589633501131},{"_id":"themes/Minos/layout/comment/gitment.ejs","hash":"430416210933b7edcbfcc67ede4aa55539da2750","modified":1589633501132},{"_id":"themes/Minos/layout/comment/livere.ejs","hash":"12ff9a345f6bba2f732f592e39508c2afde89b00","modified":1589633501132},{"_id":"themes/Minos/layout/comment/isso.ejs","hash":"cc6a43bd24be764086f88ad7c5c97ff04df87e0b","modified":1589633501132},{"_id":"themes/Minos/layout/comment/valine.ejs","hash":"b0eef3bea0a54b4b66f860ad69889f87e0408f22","modified":1589633501132},{"_id":"themes/Minos/layout/comment/youyan.ejs","hash":"3d6cf9c523a7a5510ec2864bb29f861f9bb78af3","modified":1589633501132},{"_id":"themes/Minos/layout/common/article.ejs","hash":"45d276fb6bfcee6690cfffa7cbdec18709cd8766","modified":1589633501132},{"_id":"themes/Minos/layout/common/footer.ejs","hash":"367c5f2e69c66d4d6fbd8beeade0b60024ce9e6e","modified":1589638230789},{"_id":"themes/Minos/layout/common/head.ejs","hash":"4dd9352ea5f5a59d3af2bedac7d545c08bb08531","modified":1589633501133},{"_id":"themes/Minos/layout/common/languages.ejs","hash":"89665c656a1ffebc9c97f03e7f9c12dd1d90702a","modified":1589633501133},{"_id":"themes/Minos/layout/common/navbar.ejs","hash":"f3aa16f357450651d0454f1ddc06a032f3dc4de3","modified":1589633501133},{"_id":"themes/Minos/layout/common/paginator.ejs","hash":"8f5060e4c8a86a3f4e58455c41c98e831e23e4a4","modified":1589633501133},{"_id":"themes/Minos/layout/common/scripts.ejs","hash":"7a5a5271930423b95046836597e30e31fa708f66","modified":1589633501133},{"_id":"themes/Minos/layout/plugins/clipboard.ejs","hash":"a448757bb8a2c29bd9501c625f7df5087bb18dbe","modified":1589633501134},{"_id":"themes/Minos/layout/plugins/gallery.ejs","hash":"7c2becafdf6b60e677cdd5756b9d55eba2af4944","modified":1589633501134},{"_id":"themes/Minos/layout/plugins/google-analytics.ejs","hash":"2a9d944a60aff7df27def5215bdc071e605c3c42","modified":1589633501134},{"_id":"themes/Minos/layout/plugins/mathjax.ejs","hash":"b92fc2b30040e09145d80ebb9bad6813dda8acf2","modified":1589633501135},{"_id":"themes/Minos/layout/plugins/katex.ejs","hash":"c8a7ecdc5802007f8fec46a299790ce4e0834acd","modified":1589633501135},{"_id":"themes/Minos/layout/search/google-cse.ejs","hash":"a6bf5c30339735126efa7efa684f9eb14dd6136a","modified":1589633501135},{"_id":"themes/Minos/layout/search/insight.ejs","hash":"6fb7d27ef40145d8587b46b44a43516135b5a81a","modified":1589633501135},{"_id":"themes/Minos/layout/share/addthis.ejs","hash":"f1c5f337333009d5f00dfbac4864a16ef8f9cb8d","modified":1589633501136},{"_id":"themes/Minos/layout/share/sharethis.ejs","hash":"4f2c40f790f3be0a4e79db04f02ea41ba2f4d4c0","modified":1589633501136},{"_id":"themes/Minos/source/css/insight.scss","hash":"f785fc6574d2853c660be39b2e3149d4846b577f","modified":1589633501138},{"_id":"themes/Minos/source/images/check.svg","hash":"029b8b3523b7daa4005983b4463cd93408308aab","modified":1589633501139},{"_id":"themes/Minos/source/css/style.scss","hash":"ca4aed6487522a02e0b8f602d2e0542f233ac818","modified":1589633501139},{"_id":"themes/Minos/source/images/exclamation.svg","hash":"b2db56f2cc13fce73dbea46c7b446d9bcb3bf0fd","modified":1589633501139},{"_id":"themes/Minos/source/images/info.svg","hash":"c8aa387e935ba9a7fa72c5dd000b7d46f2e030c4","modified":1589633501139},{"_id":"themes/Minos/source/images/question.svg","hash":"7153fa2a0c21e32da6a1f96a333d8b66a178569d","modified":1589633501139},{"_id":"themes/Minos/source/images/logo.png","hash":"4e012d9ba58cb8f87ee775262ef871c158ac5948","modified":1589633501139},{"_id":"themes/Minos/source/images/quote-left.svg","hash":"d2561fa8d13e63ff196b71232a5968415ec6e372","modified":1589633501140},{"_id":"themes/Minos/source/js/insight.js","hash":"eb23c31141784eef7300f1d1c548950e77883f56","modified":1589633501140},{"_id":"themes/Minos/source/js/script.js","hash":"6b670ec4f90fb43b21a0bbd750a217af5d8aab6b","modified":1589633501140},{"_id":"source/_posts/The-mechanism-behind-WriteBatch-in-leveldb.md","hash":"a290eeafcaddc5016cb0b984a2b19b67c532bb89","modified":1589638594005},{"_id":"source/_posts/The-mechanism-behind-WriteBatch-in-leveldb/rep_format.png","hash":"a6092fa1672562a55d6b2f8e7c1fbf175e5ae5e6","modified":1589634314135},{"_id":"source/_posts/Redo-log-in-InnoDB.md","hash":"22ba11f9872a3436fb83b471f9aa6941a81f2fb2","modified":1589638514110},{"_id":"source/_posts/Redo-log-in-InnoDB/redo-log-block.jpg","hash":"bc4cc2268ef18f396963a27433a46de92d757d04","modified":1589635263857},{"_id":"source/_posts/Compile-your-own-linux-kernel.md","hash":"ecda67ac809f91ede21f812b3319e5d9114ea4ef","modified":1589638550082},{"_id":"source/_posts/Compile-your-own-linux-kernel/kernel-booting.png","hash":"c893fdae2c89ce5425baa0de6fa14927748bd871","modified":1589636093486},{"_id":"source/_posts/Compile-your-own-linux-kernel/kernel-directory.png","hash":"5912734b56fbb305f241128a69043bc3c1adea6e","modified":1589636028529},{"_id":"source/_posts/Compile-your-own-linux-kernel/kernel-configuration.png","hash":"ca26873142863858ea26deeed08516965e5025bc","modified":1589636053175},{"_id":"source/_posts/Compile-your-own-linux-kernel/kernel-grub.png","hash":"1d32e766359978deb091128bc690f360c83cb646","modified":1589636081674},{"_id":"source/_posts/Compile-your-own-linux-kernel/kernel-menuconfig.png","hash":"7ed118cc58f05e7ffe961290bcd2337f406ba72a","modified":1589636066610},{"_id":"source/_posts/Read-and-Write-functions-in-linux.md","hash":"5d1450869c115e3d0729091a0c0154b4713a18df","modified":1589638566995},{"_id":"public/content.json","hash":"0d62967787e37022e7a819a288f3ec4955ce167b","modified":1589821083584},{"_id":"public/2016/07/09/Redo-log-in-InnoDB/index.html","hash":"fc89c5b4de734006c680b61ad358ba36d8a84248","modified":1589821083584},{"_id":"public/2016/04/12/Read-and-Write-functions-in-linux/index.html","hash":"06f2c2a44e43d34f3cfb9df3e0e2be97d8e3d88a","modified":1589821083584},{"_id":"public/archives/index.html","hash":"e78e574bee53ad2a55041389bcb5c292ba690ff0","modified":1589821083584},{"_id":"public/archives/2016/index.html","hash":"8733c423513d32ae66d21c4da483afcd1386d708","modified":1589821083584},{"_id":"public/archives/2016/03/index.html","hash":"00fc38fd54a5cc6cf22e3d06d733ac9078eebed2","modified":1589821083584},{"_id":"public/archives/2016/04/index.html","hash":"9c1b7d0a99c6899f90d562f3a3951c79e65930fd","modified":1589821083584},{"_id":"public/archives/2016/07/index.html","hash":"2ca6722f6ec02dc021890652a040bda1dcca0257","modified":1589821083584},{"_id":"public/archives/2020/index.html","hash":"494935d7a89af68819c6a01aef234b1f6911c3d4","modified":1589821083584},{"_id":"public/archives/2020/05/index.html","hash":"4b22144191a8d8e33b92576d95dfb5196ecf2bc2","modified":1589821083584},{"_id":"public/index.html","hash":"16dadaeff104edf63949cea6275ea20393bf7aa6","modified":1589821083584},{"_id":"public/tags/database/index.html","hash":"a890ef6c43b9036554113c48337a6c577d86c704","modified":1589821083584},{"_id":"public/tags/kernel/index.html","hash":"c19e35b6cdb27b0215730f256cf8f57d2b6967d9","modified":1589821083584},{"_id":"public/tags/linux/index.html","hash":"b273b01cc4b53a51d3600d60c2a302c34a2660ad","modified":1589821083584},{"_id":"public/categories/Technology/index.html","hash":"a281371569042b0de7713480bb32d1ca904fe83a","modified":1589821083584},{"_id":"public/categories/index.html","hash":"c42201661e5c83d1dee63c0425d009599f37171f","modified":1589821083584},{"_id":"public/tags/index.html","hash":"2749cefedcf6e4550446b78d4f506b427777b010","modified":1589821083584},{"_id":"public/2020/05/16/The-mechanism-behind-WriteBatch-in-leveldb/index.html","hash":"98dbd7c2a2ac3e2959b6b7381b5bed38884b781f","modified":1589821083584},{"_id":"public/2016/03/23/Compile-your-own-linux-kernel/index.html","hash":"da26ecf0c73af8c81bbf44df968f951614c102e0","modified":1589821083584},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1589638305277},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1589638305277},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1589638305277},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1589638305277},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1589638305277},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1589638305277},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1589638305277},{"_id":"public/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1589638305277},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1589638305277},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1589638305277},{"_id":"public/images/check.svg","hash":"029b8b3523b7daa4005983b4463cd93408308aab","modified":1589638305277},{"_id":"public/images/logo.png","hash":"4e012d9ba58cb8f87ee775262ef871c158ac5948","modified":1589638305277},{"_id":"public/images/exclamation.svg","hash":"b2db56f2cc13fce73dbea46c7b446d9bcb3bf0fd","modified":1589638305277},{"_id":"public/images/info.svg","hash":"c8aa387e935ba9a7fa72c5dd000b7d46f2e030c4","modified":1589638305277},{"_id":"public/images/question.svg","hash":"7153fa2a0c21e32da6a1f96a333d8b66a178569d","modified":1589638305277},{"_id":"public/images/quote-left.svg","hash":"d2561fa8d13e63ff196b71232a5968415ec6e372","modified":1589638305277},{"_id":"public/2016/07/09/Redo-log-in-InnoDB/redo-log-block.jpg","hash":"bc4cc2268ef18f396963a27433a46de92d757d04","modified":1589638305277},{"_id":"public/2016/03/23/Compile-your-own-linux-kernel/kernel-booting.png","hash":"c893fdae2c89ce5425baa0de6fa14927748bd871","modified":1589638305277},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1589638305277},{"_id":"public/2020/05/16/The-mechanism-behind-WriteBatch-in-leveldb/rep_format.png","hash":"a6092fa1672562a55d6b2f8e7c1fbf175e5ae5e6","modified":1589638305277},{"_id":"public/2016/03/23/Compile-your-own-linux-kernel/kernel-grub.png","hash":"1d32e766359978deb091128bc690f360c83cb646","modified":1589638305277},{"_id":"public/2016/03/23/Compile-your-own-linux-kernel/kernel-directory.png","hash":"5912734b56fbb305f241128a69043bc3c1adea6e","modified":1589638305277},{"_id":"public/css/style.css","hash":"4e7a159e292129b1abbdcabc69aad37c4eb5fc8e","modified":1589638305277},{"_id":"public/js/script.js","hash":"6b670ec4f90fb43b21a0bbd750a217af5d8aab6b","modified":1589638305277},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1589638305277},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1589638305277},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1589638305277},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1589638305277},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1589638305277},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1589638305277},{"_id":"public/css/insight.css","hash":"f376dcda6bb50b708f3206c15a49f7530b3c534d","modified":1589638305277},{"_id":"public/js/insight.js","hash":"eb23c31141784eef7300f1d1c548950e77883f56","modified":1589638305277},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1589638305277},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1589638305277},{"_id":"public/2016/03/23/Compile-your-own-linux-kernel/kernel-menuconfig.png","hash":"7ed118cc58f05e7ffe961290bcd2337f406ba72a","modified":1589638305277},{"_id":"public/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1589638305277},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1589638305277},{"_id":"public/2016/03/23/Compile-your-own-linux-kernel/kernel-configuration.png","hash":"ca26873142863858ea26deeed08516965e5025bc","modified":1589638305277},{"_id":"themes/Minos/_config.yml","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1589819172601},{"_id":"public/tags/C/index.html","hash":"e347568de3a58fe3d5200a1b95eb399741cdb46a","modified":1589821083584},{"_id":"public/tags/mysql/index.html","hash":"57a615476a53b531949d7b769b7661871159ffe7","modified":1589821083584},{"_id":"public/tags/leveldb/index.html","hash":"b0fa2f00dc7592372f29a78ad294cc28d0abc3b5","modified":1589821083584}],"Category":[{"name":"Technology","_id":"cka9pgaji0000rppkhq8jbvzn"}],"Data":[],"Page":[],"Post":[{"title":"The mechanism behind WriteBatch in leveldb","date":"2020-05-16T12:59:09.000Z","_content":"\n### Introduction\n\nAs a well-known key-value database,[ leveldb](https://github.com/google/leveldb) provides general key-values interfaces like Put, Get and Delete. Besides those interfaces, leveldb provides a batch operation called WriteBatch as well. A batch operation means we can group multiple operations into one and submit this one to leveldb, the atomicity guarantees that either all of those operations are applied or none of them is applied.\n\nFor example, we can use batch operation in leveldb in the following way:\n\n```C++\nWriteBatch b;\nbatch.Put(\"key\", \"v1\");\nbatch.Delete(\"key\");\nbatch.Put(\"key\", \"v2\");\nbatch.Put(\"key\", \"v3\");\ndb->Write(WriteOptions(), &b);\n```\n\nThe updates are applied in the order in which they are added to the WriteBatch. And the value of \"key\" in the above code sample will be \"v3\" after the batch is written.\n\n### Implementaion of WriteBatch\n\nWell, how does leveldb implement this simple but powerful interface? Let's figure it out by digging the source code step by step.\n\n<!-- more -->\n\n\n\n#### WriteBatch Class\n\nThe `WriteBatch` is a class containing member function `WriteBatch::Put`, `WriteBatch::Delete`,`WriteBatch::Clear` and `WriteBatch::Iterate`. A private member variable of string type called `rep_` is also owned by it.\n\n\n\nIn the constructor of `WriteBatch`, `rep_` is cleared firstly and resize to length `kHeader`:\n\n```c++\nstatic const size_t kHeader = 12;\n\nWriteBatch::WriteBatch() {\n  Clear();\n}\n\nvoid WriteBatch::Clear() {\n  rep_.clear();\n  rep_.resize(kHeader);\n}\n```\n\nThat's because the first `kHeader` bytes in `rep_` is used to maintain meta information: 8-byte sequence number and followed by a 4-byte count.\n\n\n\nEach time when the user calls `WriteBatch::Put`, the `rep_` variable gets updated by the following behaviors :\n\n```C++\nvoid WriteBatch::Put(const Slice& key, const Slice& value) {\n  WriteBatchInternal::SetCount(this, WriteBatchInternal::Count(this) + 1);\n  rep_.push_back(static_cast<char>(kTypeValue));\n  PutLengthPrefixedSlice(&rep_, key);\n  PutLengthPrefixedSlice(&rep_, value);\n}\n```\n\nConsequently, the 4-byte count in `rep_` gets incremented, and an enum char value `kTypeValue`(means this is a put operation), the key and the value are appended into the end of `rep_`.\n\n\n\nSimilarly, when the user calls `WriteBatch::Delete`, the `rep_` variable is updated in a similar way:\n\n```C++\nvoid WriteBatch::Delete(const Slice& key) {\n  WriteBatchInternal::SetCount(this, WriteBatchInternal::Count(this) + 1);\n  rep_.push_back(static_cast<char>(kTypeDeletion));\n  PutLengthPrefixedSlice(&rep_, key);\n}\n```\n\nExcepting that an enum char value `kTypeDeletion`(means this is a put operation) and the key information are appended into the `rep_`.\n\n\n\nLet's be more specific about the function `PutLengthPrefixedSlice` called by both `WriteBatch::Delete`and `WriteBatch::Put`:\n\n```C++\nvoid PutLengthPrefixedSlice(std::string* dst, const Slice& value) {\n  PutVarint32(dst, value.size());\n  dst->append(value.data(), value.size());\n}\n```\n\nIt appends the value size into dst and then the value itself into dst.\n\nBased on all the information provided above, we know that the `Put` and `Delete` member function of `WriteBatch` only update its member variable `rep_`. \n\nAnd we can also know the data layout format of `rep_`: \n\n```\nWriteBatch::rep_ :=\n      sequence: fixed64\n      count: fixed32\n      data: record[count]\nrecord :=\n      kTypeValue varstring varstring         |\n      kTypeDeletion varstring\nvarstring :=\n      len: varint32\n      data: uint8[len]\n```\n\n{% asset_img rep_format.png image of rep_ format %}\n\n\n\n#### DBImpl::Write\n\nAfter a batch operation is encapsulated, it's time to call `DBImpl::Write` to apply the batch operation into the underlying layer to persist it.\n\nInside `DBImpl::Write`, an instance of `Writer` called `w` , which represents the batch operation context, is created and added to the end of the double-ended queue `writers_`.  Because write operation is in strict order, so the write thread must wait until `w` is the first element of `writers_`.\n\n```c++\nWriter w(&mutex_);\n  w.batch = my_batch;\n  w.sync = options.sync;\n  w.done = false;\n\n  MutexLock l(&mutex_);\n  writers_.push_back(&w);\n  while (!w.done && &w != writers_.front()) {\n    w.cv.Wait();\n  }\n  if (w.done) {\n    return w.status;\n  }\n```\n\n\n\nWhen the condition is fulfilled, leveldb will make sure there is enough room for this batch operation. Enough room mainly means memtable is prepared well to handle this write (I will write another new article to talk about that). Because `w` becomes the first element in `writers_`, the write thread will try to group other writers behind `w` into a so-called `BatchGroup` to speed up the io efficiency by the function `DBImpl::BuildBatchGroup`.\n\n```c++\nWriteBatch* DBImpl::BuildBatchGroup(Writer** last_writer) {\n  assert(!writers_.empty());\n  Writer* first = writers_.front();\n  WriteBatch* result = first->batch;\n  assert(result != NULL);\n\n  size_t size = WriteBatchInternal::ByteSize(first->batch);\n\n  // Allow the group to grow up to a maximum size, but if the\n  // original write is small, limit the growth so we do not slow\n  // down the small write too much.\n  size_t max_size = 1 << 20; // 1M\n  if (size <= (128<<10)) { // 128K\n    max_size = size + (128<<10);\n  }\n\n  *last_writer = first;\n  std::deque<Writer*>::iterator iter = writers_.begin();\n  ++iter;  // Advance past \"first\"\n  for (; iter != writers_.end(); ++iter) {\n    Writer* w = *iter;\n    if (w->sync && !first->sync) {\n      // Do not include a sync write into a batch handled by a non-sync write.\n      break;\n    }\n\n    if (w->batch != NULL) {\n      size += WriteBatchInternal::ByteSize(w->batch);\n      if (size > max_size) {\n        // Do not make batch too big\n        break;\n      }\n\n      // Append to *result\n      if (result == first->batch) {\n        // Switch to temporary batch instead of disturbing caller's batch\n        result = tmp_batch_;\n        assert(WriteBatchInternal::Count(result) == 0);\n        WriteBatchInternal::Append(result, first->batch);\n      }\n      WriteBatchInternal::Append(result, w->batch);\n    }\n    *last_writer = w;\n  }\n  return result;\n}\n```\n\nInside `DBImpl::BuildBatchGroup`, it will traverse the whole `writers_` from beginning to end and try to group all  those batches into one batch. For convenience to clarify, we call this procedure \"batch mergence\"\n\nHowever, there are some limitations in batch mergence. First, the maximum size of `rep_` in the merged batch group is **1M** and if the first writer is a small writer(`rep_.size() <= 128K` ) it will limit the maximum size to `rep_.size() + 128K`. The idea behind this is not slowing down the small write too much. Second, it will not include a sync write into the batch handled by a non-sync write.\n\nIn the batch mergence, with the help of `WriteBatchInternal::Append`, the data field of `rep_` in second batch is appended to the end of the `rep_` in first batch:\n\n```c++\nvoid WriteBatchInternal::Append(WriteBatch* dst, const WriteBatch* src) {\n  SetCount(dst, Count(dst) + Count(src));\n  assert(src->rep_.size() >= kHeader);\n  dst->rep_.append(src->rep_.data() + kHeader, src->rep_.size() - kHeader);\n}\n```\n\nAfter batch mergence is finished, a new batch called `updates` is generated. And the sequence number in `rep_` of `updates` is set to `last_sequence + 1`, `last_sequnce` gets adjusted to a new one(`last_sequnce = last_sequnce + count field rep_ of updates`) as well.\n\n\n\nNow, we come to the IO critical path. The WAL in leveldb will persist the contents of the `update` in an append-only way. After that success, memtable will replay the operations in the batch `update` and do corresponding behavior in memtable:\n\n\n\nApply to WAL and insert into memtable:\n\n```c++\n{\n      mutex_.Unlock();\n      status = log_->AddRecord(WriteBatchInternal::Contents(updates));\n      bool sync_error = false;\n      if (status.ok() && options.sync) {\n        status = logfile_->Sync();\n        if (!status.ok()) {\n          sync_error = true;\n        }\n      }\n      if (status.ok()) {\n        status = WriteBatchInternal::InsertInto(updates, mem_);\n      }\n      mutex_.Lock();\n      if (sync_error) {\n        // The state of the log file is indeterminate: the log record we\n        // just added may or may not show up when the DB is re-opened.\n        // So we force the DB into a mode where all future writes fail.\n        RecordBackgroundError(status);\n      }\n    }\n```\n\n\n\n`WriteBatch` Parse the whole `rep_` string to replay original operations specified by users and call handler(MemTableInserter) to handle these operations.\n\n```\nStatus WriteBatch::Iterate(Handler* handler) const {\n  Slice input(rep_);\n  if (input.size() < kHeader) {\n    return Status::Corruption(\"malformed WriteBatch (too small)\");\n  }\n\n  input.remove_prefix(kHeader);\n  Slice key, value;\n  int found = 0;\n  while (!input.empty()) {\n    found++;\n    char tag = input[0];\n    input.remove_prefix(1);\n    switch (tag) {\n      case kTypeValue:\n        if (GetLengthPrefixedSlice(&input, &key) &&\n            GetLengthPrefixedSlice(&input, &value)) {\n          handler->Put(key, value);\n        } else {\n          return Status::Corruption(\"bad WriteBatch Put\");\n        }\n        break;\n      case kTypeDeletion:\n        if (GetLengthPrefixedSlice(&input, &key)) {\n          handler->Delete(key);\n        } else {\n          return Status::Corruption(\"bad WriteBatch Delete\");\n        }\n        break;\n      default:\n        return Status::Corruption(\"unknown WriteBatch tag\");\n    }\n  }\n  if (found != WriteBatchInternal::Count(this)) {\n    return Status::Corruption(\"WriteBatch has wrong count\");\n  } else {\n    return Status::OK();\n  }\n}\n```\n\n\n\n### Summary\n\nHoo, finally get here! This article mainly talks about how batch operation is handled in leveldb. Due to space limitation, other import parts like WAL and Memtable in leveldb cannot be presented here.\n\nHave fun~~~\n\n","source":"_posts/The-mechanism-behind-WriteBatch-in-leveldb.md","raw":"---\ntitle: The mechanism behind WriteBatch in leveldb\ndate: 2020-05-16 20:59:09\ntags: [database, leveldb]\ncategories: Technology\n---\n\n### Introduction\n\nAs a well-known key-value database,[ leveldb](https://github.com/google/leveldb) provides general key-values interfaces like Put, Get and Delete. Besides those interfaces, leveldb provides a batch operation called WriteBatch as well. A batch operation means we can group multiple operations into one and submit this one to leveldb, the atomicity guarantees that either all of those operations are applied or none of them is applied.\n\nFor example, we can use batch operation in leveldb in the following way:\n\n```C++\nWriteBatch b;\nbatch.Put(\"key\", \"v1\");\nbatch.Delete(\"key\");\nbatch.Put(\"key\", \"v2\");\nbatch.Put(\"key\", \"v3\");\ndb->Write(WriteOptions(), &b);\n```\n\nThe updates are applied in the order in which they are added to the WriteBatch. And the value of \"key\" in the above code sample will be \"v3\" after the batch is written.\n\n### Implementaion of WriteBatch\n\nWell, how does leveldb implement this simple but powerful interface? Let's figure it out by digging the source code step by step.\n\n<!-- more -->\n\n\n\n#### WriteBatch Class\n\nThe `WriteBatch` is a class containing member function `WriteBatch::Put`, `WriteBatch::Delete`,`WriteBatch::Clear` and `WriteBatch::Iterate`. A private member variable of string type called `rep_` is also owned by it.\n\n\n\nIn the constructor of `WriteBatch`, `rep_` is cleared firstly and resize to length `kHeader`:\n\n```c++\nstatic const size_t kHeader = 12;\n\nWriteBatch::WriteBatch() {\n  Clear();\n}\n\nvoid WriteBatch::Clear() {\n  rep_.clear();\n  rep_.resize(kHeader);\n}\n```\n\nThat's because the first `kHeader` bytes in `rep_` is used to maintain meta information: 8-byte sequence number and followed by a 4-byte count.\n\n\n\nEach time when the user calls `WriteBatch::Put`, the `rep_` variable gets updated by the following behaviors :\n\n```C++\nvoid WriteBatch::Put(const Slice& key, const Slice& value) {\n  WriteBatchInternal::SetCount(this, WriteBatchInternal::Count(this) + 1);\n  rep_.push_back(static_cast<char>(kTypeValue));\n  PutLengthPrefixedSlice(&rep_, key);\n  PutLengthPrefixedSlice(&rep_, value);\n}\n```\n\nConsequently, the 4-byte count in `rep_` gets incremented, and an enum char value `kTypeValue`(means this is a put operation), the key and the value are appended into the end of `rep_`.\n\n\n\nSimilarly, when the user calls `WriteBatch::Delete`, the `rep_` variable is updated in a similar way:\n\n```C++\nvoid WriteBatch::Delete(const Slice& key) {\n  WriteBatchInternal::SetCount(this, WriteBatchInternal::Count(this) + 1);\n  rep_.push_back(static_cast<char>(kTypeDeletion));\n  PutLengthPrefixedSlice(&rep_, key);\n}\n```\n\nExcepting that an enum char value `kTypeDeletion`(means this is a put operation) and the key information are appended into the `rep_`.\n\n\n\nLet's be more specific about the function `PutLengthPrefixedSlice` called by both `WriteBatch::Delete`and `WriteBatch::Put`:\n\n```C++\nvoid PutLengthPrefixedSlice(std::string* dst, const Slice& value) {\n  PutVarint32(dst, value.size());\n  dst->append(value.data(), value.size());\n}\n```\n\nIt appends the value size into dst and then the value itself into dst.\n\nBased on all the information provided above, we know that the `Put` and `Delete` member function of `WriteBatch` only update its member variable `rep_`. \n\nAnd we can also know the data layout format of `rep_`: \n\n```\nWriteBatch::rep_ :=\n      sequence: fixed64\n      count: fixed32\n      data: record[count]\nrecord :=\n      kTypeValue varstring varstring         |\n      kTypeDeletion varstring\nvarstring :=\n      len: varint32\n      data: uint8[len]\n```\n\n{% asset_img rep_format.png image of rep_ format %}\n\n\n\n#### DBImpl::Write\n\nAfter a batch operation is encapsulated, it's time to call `DBImpl::Write` to apply the batch operation into the underlying layer to persist it.\n\nInside `DBImpl::Write`, an instance of `Writer` called `w` , which represents the batch operation context, is created and added to the end of the double-ended queue `writers_`.  Because write operation is in strict order, so the write thread must wait until `w` is the first element of `writers_`.\n\n```c++\nWriter w(&mutex_);\n  w.batch = my_batch;\n  w.sync = options.sync;\n  w.done = false;\n\n  MutexLock l(&mutex_);\n  writers_.push_back(&w);\n  while (!w.done && &w != writers_.front()) {\n    w.cv.Wait();\n  }\n  if (w.done) {\n    return w.status;\n  }\n```\n\n\n\nWhen the condition is fulfilled, leveldb will make sure there is enough room for this batch operation. Enough room mainly means memtable is prepared well to handle this write (I will write another new article to talk about that). Because `w` becomes the first element in `writers_`, the write thread will try to group other writers behind `w` into a so-called `BatchGroup` to speed up the io efficiency by the function `DBImpl::BuildBatchGroup`.\n\n```c++\nWriteBatch* DBImpl::BuildBatchGroup(Writer** last_writer) {\n  assert(!writers_.empty());\n  Writer* first = writers_.front();\n  WriteBatch* result = first->batch;\n  assert(result != NULL);\n\n  size_t size = WriteBatchInternal::ByteSize(first->batch);\n\n  // Allow the group to grow up to a maximum size, but if the\n  // original write is small, limit the growth so we do not slow\n  // down the small write too much.\n  size_t max_size = 1 << 20; // 1M\n  if (size <= (128<<10)) { // 128K\n    max_size = size + (128<<10);\n  }\n\n  *last_writer = first;\n  std::deque<Writer*>::iterator iter = writers_.begin();\n  ++iter;  // Advance past \"first\"\n  for (; iter != writers_.end(); ++iter) {\n    Writer* w = *iter;\n    if (w->sync && !first->sync) {\n      // Do not include a sync write into a batch handled by a non-sync write.\n      break;\n    }\n\n    if (w->batch != NULL) {\n      size += WriteBatchInternal::ByteSize(w->batch);\n      if (size > max_size) {\n        // Do not make batch too big\n        break;\n      }\n\n      // Append to *result\n      if (result == first->batch) {\n        // Switch to temporary batch instead of disturbing caller's batch\n        result = tmp_batch_;\n        assert(WriteBatchInternal::Count(result) == 0);\n        WriteBatchInternal::Append(result, first->batch);\n      }\n      WriteBatchInternal::Append(result, w->batch);\n    }\n    *last_writer = w;\n  }\n  return result;\n}\n```\n\nInside `DBImpl::BuildBatchGroup`, it will traverse the whole `writers_` from beginning to end and try to group all  those batches into one batch. For convenience to clarify, we call this procedure \"batch mergence\"\n\nHowever, there are some limitations in batch mergence. First, the maximum size of `rep_` in the merged batch group is **1M** and if the first writer is a small writer(`rep_.size() <= 128K` ) it will limit the maximum size to `rep_.size() + 128K`. The idea behind this is not slowing down the small write too much. Second, it will not include a sync write into the batch handled by a non-sync write.\n\nIn the batch mergence, with the help of `WriteBatchInternal::Append`, the data field of `rep_` in second batch is appended to the end of the `rep_` in first batch:\n\n```c++\nvoid WriteBatchInternal::Append(WriteBatch* dst, const WriteBatch* src) {\n  SetCount(dst, Count(dst) + Count(src));\n  assert(src->rep_.size() >= kHeader);\n  dst->rep_.append(src->rep_.data() + kHeader, src->rep_.size() - kHeader);\n}\n```\n\nAfter batch mergence is finished, a new batch called `updates` is generated. And the sequence number in `rep_` of `updates` is set to `last_sequence + 1`, `last_sequnce` gets adjusted to a new one(`last_sequnce = last_sequnce + count field rep_ of updates`) as well.\n\n\n\nNow, we come to the IO critical path. The WAL in leveldb will persist the contents of the `update` in an append-only way. After that success, memtable will replay the operations in the batch `update` and do corresponding behavior in memtable:\n\n\n\nApply to WAL and insert into memtable:\n\n```c++\n{\n      mutex_.Unlock();\n      status = log_->AddRecord(WriteBatchInternal::Contents(updates));\n      bool sync_error = false;\n      if (status.ok() && options.sync) {\n        status = logfile_->Sync();\n        if (!status.ok()) {\n          sync_error = true;\n        }\n      }\n      if (status.ok()) {\n        status = WriteBatchInternal::InsertInto(updates, mem_);\n      }\n      mutex_.Lock();\n      if (sync_error) {\n        // The state of the log file is indeterminate: the log record we\n        // just added may or may not show up when the DB is re-opened.\n        // So we force the DB into a mode where all future writes fail.\n        RecordBackgroundError(status);\n      }\n    }\n```\n\n\n\n`WriteBatch` Parse the whole `rep_` string to replay original operations specified by users and call handler(MemTableInserter) to handle these operations.\n\n```\nStatus WriteBatch::Iterate(Handler* handler) const {\n  Slice input(rep_);\n  if (input.size() < kHeader) {\n    return Status::Corruption(\"malformed WriteBatch (too small)\");\n  }\n\n  input.remove_prefix(kHeader);\n  Slice key, value;\n  int found = 0;\n  while (!input.empty()) {\n    found++;\n    char tag = input[0];\n    input.remove_prefix(1);\n    switch (tag) {\n      case kTypeValue:\n        if (GetLengthPrefixedSlice(&input, &key) &&\n            GetLengthPrefixedSlice(&input, &value)) {\n          handler->Put(key, value);\n        } else {\n          return Status::Corruption(\"bad WriteBatch Put\");\n        }\n        break;\n      case kTypeDeletion:\n        if (GetLengthPrefixedSlice(&input, &key)) {\n          handler->Delete(key);\n        } else {\n          return Status::Corruption(\"bad WriteBatch Delete\");\n        }\n        break;\n      default:\n        return Status::Corruption(\"unknown WriteBatch tag\");\n    }\n  }\n  if (found != WriteBatchInternal::Count(this)) {\n    return Status::Corruption(\"WriteBatch has wrong count\");\n  } else {\n    return Status::OK();\n  }\n}\n```\n\n\n\n### Summary\n\nHoo, finally get here! This article mainly talks about how batch operation is handled in leveldb. Due to space limitation, other import parts like WAL and Memtable in leveldb cannot be presented here.\n\nHave fun~~~\n\n","slug":"The-mechanism-behind-WriteBatch-in-leveldb","published":1,"updated":"2020-05-16T14:16:34.005Z","_id":"cka9n1t1y0000grpkegovf6kg","comments":1,"layout":"post","photos":[],"link":"","content":"<html><head></head><body><h3 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h3><p>As a well-known key-value database,<a href=\"https://github.com/google/leveldb\" target=\"_blank\" rel=\"noopener\"> leveldb</a> provides general key-values interfaces like Put, Get and Delete. Besides those interfaces, leveldb provides a batch operation called WriteBatch as well. A batch operation means we can group multiple operations into one and submit this one to leveldb, the atomicity guarantees that either all of those operations are applied or none of them is applied.</p>\n<p>For example, we can use batch operation in leveldb in the following way:</p>\n<p></p><figure class=\"highlight c++ hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WriteBatch b;</span><br><span class=\"line\">batch.Put(<span class=\"hljs-string\">&quot;key&quot;</span>, <span class=\"hljs-string\">&quot;v1&quot;</span>);</span><br><span class=\"line\">batch.Delete(<span class=\"hljs-string\">&quot;key&quot;</span>);</span><br><span class=\"line\">batch.Put(<span class=\"hljs-string\">&quot;key&quot;</span>, <span class=\"hljs-string\">&quot;v2&quot;</span>);</span><br><span class=\"line\">batch.Put(<span class=\"hljs-string\">&quot;key&quot;</span>, <span class=\"hljs-string\">&quot;v3&quot;</span>);</span><br><span class=\"line\">db-&gt;Write(WriteOptions(), &amp;b);</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>The updates are applied in the order in which they are added to the WriteBatch. And the value of &#x201C;key&#x201D; in the above code sample will be &#x201C;v3&#x201D; after the batch is written.</p>\n<h3 id=\"Implementaion-of-WriteBatch\"><a href=\"#Implementaion-of-WriteBatch\" class=\"headerlink\" title=\"Implementaion of WriteBatch\"></a>Implementaion of WriteBatch</h3><p>Well, how does leveldb implement this simple but powerful interface? Let&#x2019;s figure it out by digging the source code step by step.</p>\n<a id=\"more\"></a>\n\n\n\n<h4 id=\"WriteBatch-Class\"><a href=\"#WriteBatch-Class\" class=\"headerlink\" title=\"WriteBatch Class\"></a>WriteBatch Class</h4><p>The <code>WriteBatch</code> is a class containing member function <code>WriteBatch::Put</code>, <code>WriteBatch::Delete</code>,<code>WriteBatch::Clear</code> and <code>WriteBatch::Iterate</code>. A private member variable of string type called <code>rep_</code> is also owned by it.</p>\n<p>In the constructor of <code>WriteBatch</code>, <code>rep_</code> is cleared firstly and resize to length <code>kHeader</code>:</p>\n<p></p><figure class=\"highlight c++ hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">size_t</span> kHeader = <span class=\"hljs-number\">12</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">WriteBatch::WriteBatch() {</span><br><span class=\"line\">  Clear();</span><br><span class=\"line\">}</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">WriteBatch::Clear</span><span class=\"hljs-params\">()</span> </span>{</span><br><span class=\"line\">  rep_.<span class=\"hljs-built_in\">clear</span>();</span><br><span class=\"line\">  rep_.resize(kHeader);</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>That&#x2019;s because the first <code>kHeader</code> bytes in <code>rep_</code> is used to maintain meta information: 8-byte sequence number and followed by a 4-byte count.</p>\n<p>Each time when the user calls <code>WriteBatch::Put</code>, the <code>rep_</code> variable gets updated by the following behaviors :</p>\n<p></p><figure class=\"highlight c++ hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">WriteBatch::Put</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> Slice&amp; key, <span class=\"hljs-keyword\">const</span> Slice&amp; value)</span> </span>{</span><br><span class=\"line\">  WriteBatchInternal::SetCount(<span class=\"hljs-keyword\">this</span>, WriteBatchInternal::Count(<span class=\"hljs-keyword\">this</span>) + <span class=\"hljs-number\">1</span>);</span><br><span class=\"line\">  rep_.push_back(<span class=\"hljs-keyword\">static_cast</span>&lt;<span class=\"hljs-keyword\">char</span>&gt;(kTypeValue));</span><br><span class=\"line\">  PutLengthPrefixedSlice(&amp;rep_, key);</span><br><span class=\"line\">  PutLengthPrefixedSlice(&amp;rep_, value);</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>Consequently, the 4-byte count in <code>rep_</code> gets incremented, and an enum char value <code>kTypeValue</code>(means this is a put operation), the key and the value are appended into the end of <code>rep_</code>.</p>\n<p>Similarly, when the user calls <code>WriteBatch::Delete</code>, the <code>rep_</code> variable is updated in a similar way:</p>\n<p></p><figure class=\"highlight c++ hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">WriteBatch::Delete</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> Slice&amp; key)</span> </span>{</span><br><span class=\"line\">  WriteBatchInternal::SetCount(<span class=\"hljs-keyword\">this</span>, WriteBatchInternal::Count(<span class=\"hljs-keyword\">this</span>) + <span class=\"hljs-number\">1</span>);</span><br><span class=\"line\">  rep_.push_back(<span class=\"hljs-keyword\">static_cast</span>&lt;<span class=\"hljs-keyword\">char</span>&gt;(kTypeDeletion));</span><br><span class=\"line\">  PutLengthPrefixedSlice(&amp;rep_, key);</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>Excepting that an enum char value <code>kTypeDeletion</code>(means this is a put operation) and the key information are appended into the <code>rep_</code>.</p>\n<p>Let&#x2019;s be more specific about the function <code>PutLengthPrefixedSlice</code> called by both <code>WriteBatch::Delete</code>and <code>WriteBatch::Put</code>:</p>\n<p></p><figure class=\"highlight c++ hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">PutLengthPrefixedSlice</span><span class=\"hljs-params\">(<span class=\"hljs-built_in\">std</span>::<span class=\"hljs-built_in\">string</span>* dst, <span class=\"hljs-keyword\">const</span> Slice&amp; value)</span> </span>{</span><br><span class=\"line\">  PutVarint32(dst, value.<span class=\"hljs-built_in\">size</span>());</span><br><span class=\"line\">  dst-&gt;append(value.data(), value.<span class=\"hljs-built_in\">size</span>());</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>It appends the value size into dst and then the value itself into dst.</p>\n<p>Based on all the information provided above, we know that the <code>Put</code> and <code>Delete</code> member function of <code>WriteBatch</code> only update its member variable <code>rep_</code>. </p>\n<p>And we can also know the data layout format of <code>rep_</code>: </p>\n<p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">WriteBatch::rep_ :=</span><br><span class=\"line\">      sequence: fixed64</span><br><span class=\"line\">      count: fixed32</span><br><span class=\"line\">      data: record[count]</span><br><span class=\"line\">record :=</span><br><span class=\"line\">      kTypeValue varstring varstring         |</span><br><span class=\"line\">      kTypeDeletion varstring</span><br><span class=\"line\">varstring :=</span><br><span class=\"line\">      len: varint32</span><br><span class=\"line\">      data: uint8[len]</span><br></pre></td></tr></tbody></table></figure><p></p>\n<img src=\"/2020/05/16/The-mechanism-behind-WriteBatch-in-leveldb/rep_format.png\" class title=\"image of rep_ format\">\n\n\n\n<h4 id=\"DBImpl-Write\"><a href=\"#DBImpl-Write\" class=\"headerlink\" title=\"DBImpl::Write\"></a>DBImpl::Write</h4><p>After a batch operation is encapsulated, it&#x2019;s time to call <code>DBImpl::Write</code> to apply the batch operation into the underlying layer to persist it.</p>\n<p>Inside <code>DBImpl::Write</code>, an instance of <code>Writer</code> called <code>w</code> , which represents the batch operation context, is created and added to the end of the double-ended queue <code>writers_</code>.  Because write operation is in strict order, so the write thread must wait until <code>w</code> is the first element of <code>writers_</code>.</p>\n<p></p><figure class=\"highlight c++ hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-function\">Writer <span class=\"hljs-title\">w</span><span class=\"hljs-params\">(&amp;mutex_)</span></span>;</span><br><span class=\"line\">  w.batch = my_batch;</span><br><span class=\"line\">  w.sync = options.sync;</span><br><span class=\"line\">  w.done = <span class=\"hljs-literal\">false</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"hljs-function\">MutexLock <span class=\"hljs-title\">l</span><span class=\"hljs-params\">(&amp;mutex_)</span></span>;</span><br><span class=\"line\">  writers_.push_back(&amp;w);</span><br><span class=\"line\">  <span class=\"hljs-keyword\">while</span> (!w.done &amp;&amp; &amp;w != writers_.front()) {</span><br><span class=\"line\">    w.cv.Wait();</span><br><span class=\"line\">  }</span><br><span class=\"line\">  <span class=\"hljs-keyword\">if</span> (w.done) {</span><br><span class=\"line\">    <span class=\"hljs-keyword\">return</span> w.status;</span><br><span class=\"line\">  }</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>When the condition is fulfilled, leveldb will make sure there is enough room for this batch operation. Enough room mainly means memtable is prepared well to handle this write (I will write another new article to talk about that). Because <code>w</code> becomes the first element in <code>writers_</code>, the write thread will try to group other writers behind <code>w</code> into a so-called <code>BatchGroup</code> to speed up the io efficiency by the function <code>DBImpl::BuildBatchGroup</code>.</p>\n<p></p><figure class=\"highlight c++ hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-function\">WriteBatch* <span class=\"hljs-title\">DBImpl::BuildBatchGroup</span><span class=\"hljs-params\">(Writer** last_writer)</span> </span>{</span><br><span class=\"line\">  assert(!writers_.empty());</span><br><span class=\"line\">  Writer* first = writers_.front();</span><br><span class=\"line\">  WriteBatch* result = first-&gt;batch;</span><br><span class=\"line\">  assert(result != <span class=\"hljs-literal\">NULL</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"hljs-keyword\">size_t</span> <span class=\"hljs-built_in\">size</span> = WriteBatchInternal::ByteSize(first-&gt;batch);</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"hljs-comment\">// Allow the group to grow up to a maximum size, but if the</span></span><br><span class=\"line\">  <span class=\"hljs-comment\">// original write is small, limit the growth so we do not slow</span></span><br><span class=\"line\">  <span class=\"hljs-comment\">// down the small write too much.</span></span><br><span class=\"line\">  <span class=\"hljs-keyword\">size_t</span> max_size = <span class=\"hljs-number\">1</span> &lt;&lt; <span class=\"hljs-number\">20</span>; <span class=\"hljs-comment\">// 1M</span></span><br><span class=\"line\">  <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">size</span> &lt;= (<span class=\"hljs-number\">128</span>&lt;&lt;<span class=\"hljs-number\">10</span>)) { <span class=\"hljs-comment\">// 128K</span></span><br><span class=\"line\">    max_size = <span class=\"hljs-built_in\">size</span> + (<span class=\"hljs-number\">128</span>&lt;&lt;<span class=\"hljs-number\">10</span>);</span><br><span class=\"line\">  }</span><br><span class=\"line\"></span><br><span class=\"line\">  *last_writer = first;</span><br><span class=\"line\">  <span class=\"hljs-built_in\">std</span>::<span class=\"hljs-built_in\">deque</span>&lt;Writer*&gt;::iterator iter = writers_.<span class=\"hljs-built_in\">begin</span>();</span><br><span class=\"line\">  ++iter;  <span class=\"hljs-comment\">// Advance past &quot;first&quot;</span></span><br><span class=\"line\">  <span class=\"hljs-keyword\">for</span> (; iter != writers_.<span class=\"hljs-built_in\">end</span>(); ++iter) {</span><br><span class=\"line\">    Writer* w = *iter;</span><br><span class=\"line\">    <span class=\"hljs-keyword\">if</span> (w-&gt;sync &amp;&amp; !first-&gt;sync) {</span><br><span class=\"line\">      <span class=\"hljs-comment\">// Do not include a sync write into a batch handled by a non-sync write.</span></span><br><span class=\"line\">      <span class=\"hljs-keyword\">break</span>;</span><br><span class=\"line\">    }</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"hljs-keyword\">if</span> (w-&gt;batch != <span class=\"hljs-literal\">NULL</span>) {</span><br><span class=\"line\">      <span class=\"hljs-built_in\">size</span> += WriteBatchInternal::ByteSize(w-&gt;batch);</span><br><span class=\"line\">      <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">size</span> &gt; max_size) {</span><br><span class=\"line\">        <span class=\"hljs-comment\">// Do not make batch too big</span></span><br><span class=\"line\">        <span class=\"hljs-keyword\">break</span>;</span><br><span class=\"line\">      }</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"hljs-comment\">// Append to *result</span></span><br><span class=\"line\">      <span class=\"hljs-keyword\">if</span> (result == first-&gt;batch) {</span><br><span class=\"line\">        <span class=\"hljs-comment\">// Switch to temporary batch instead of disturbing caller&apos;s batch</span></span><br><span class=\"line\">        result = tmp_batch_;</span><br><span class=\"line\">        assert(WriteBatchInternal::Count(result) == <span class=\"hljs-number\">0</span>);</span><br><span class=\"line\">        WriteBatchInternal::Append(result, first-&gt;batch);</span><br><span class=\"line\">      }</span><br><span class=\"line\">      WriteBatchInternal::Append(result, w-&gt;batch);</span><br><span class=\"line\">    }</span><br><span class=\"line\">    *last_writer = w;</span><br><span class=\"line\">  }</span><br><span class=\"line\">  <span class=\"hljs-keyword\">return</span> result;</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>Inside <code>DBImpl::BuildBatchGroup</code>, it will traverse the whole <code>writers_</code> from beginning to end and try to group all  those batches into one batch. For convenience to clarify, we call this procedure &#x201C;batch mergence&#x201D;</p>\n<p>However, there are some limitations in batch mergence. First, the maximum size of <code>rep_</code> in the merged batch group is <strong>1M</strong> and if the first writer is a small writer(<code>rep_.size() &lt;= 128K</code> ) it will limit the maximum size to <code>rep_.size() + 128K</code>. The idea behind this is not slowing down the small write too much. Second, it will not include a sync write into the batch handled by a non-sync write.</p>\n<p>In the batch mergence, with the help of <code>WriteBatchInternal::Append</code>, the data field of <code>rep_</code> in second batch is appended to the end of the <code>rep_</code> in first batch:</p>\n<p></p><figure class=\"highlight c++ hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">WriteBatchInternal::Append</span><span class=\"hljs-params\">(WriteBatch* dst, <span class=\"hljs-keyword\">const</span> WriteBatch* src)</span> </span>{</span><br><span class=\"line\">  SetCount(dst, Count(dst) + Count(src));</span><br><span class=\"line\">  assert(src-&gt;rep_.<span class=\"hljs-built_in\">size</span>() &gt;= kHeader);</span><br><span class=\"line\">  dst-&gt;rep_.append(src-&gt;rep_.data() + kHeader, src-&gt;rep_.<span class=\"hljs-built_in\">size</span>() - kHeader);</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>After batch mergence is finished, a new batch called <code>updates</code> is generated. And the sequence number in <code>rep_</code> of <code>updates</code> is set to <code>last_sequence + 1</code>, <code>last_sequnce</code> gets adjusted to a new one(<code>last_sequnce = last_sequnce + count field rep_ of updates</code>) as well.</p>\n<p>Now, we come to the IO critical path. The WAL in leveldb will persist the contents of the <code>update</code> in an append-only way. After that success, memtable will replay the operations in the batch <code>update</code> and do corresponding behavior in memtable:</p>\n<p>Apply to WAL and insert into memtable:</p>\n<p></p><figure class=\"highlight c++ hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">{</span><br><span class=\"line\">      mutex_.Unlock();</span><br><span class=\"line\">      status = log_-&gt;AddRecord(WriteBatchInternal::Contents(updates));</span><br><span class=\"line\">      <span class=\"hljs-keyword\">bool</span> sync_error = <span class=\"hljs-literal\">false</span>;</span><br><span class=\"line\">      <span class=\"hljs-keyword\">if</span> (status.ok() &amp;&amp; options.sync) {</span><br><span class=\"line\">        status = logfile_-&gt;Sync();</span><br><span class=\"line\">        <span class=\"hljs-keyword\">if</span> (!status.ok()) {</span><br><span class=\"line\">          sync_error = <span class=\"hljs-literal\">true</span>;</span><br><span class=\"line\">        }</span><br><span class=\"line\">      }</span><br><span class=\"line\">      <span class=\"hljs-keyword\">if</span> (status.ok()) {</span><br><span class=\"line\">        status = WriteBatchInternal::InsertInto(updates, mem_);</span><br><span class=\"line\">      }</span><br><span class=\"line\">      mutex_.Lock();</span><br><span class=\"line\">      <span class=\"hljs-keyword\">if</span> (sync_error) {</span><br><span class=\"line\">        <span class=\"hljs-comment\">// The state of the log file is indeterminate: the log record we</span></span><br><span class=\"line\">        <span class=\"hljs-comment\">// just added may or may not show up when the DB is re-opened.</span></span><br><span class=\"line\">        <span class=\"hljs-comment\">// So we force the DB into a mode where all future writes fail.</span></span><br><span class=\"line\">        RecordBackgroundError(status);</span><br><span class=\"line\">      }</span><br><span class=\"line\">    }</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p><code>WriteBatch</code> Parse the whole <code>rep_</code> string to replay original operations specified by users and call handler(MemTableInserter) to handle these operations.</p>\n<p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Status WriteBatch::Iterate(Handler* handler) const {</span><br><span class=\"line\">  Slice input(rep_);</span><br><span class=\"line\">  if (input.size() &lt; kHeader) {</span><br><span class=\"line\">    return Status::Corruption(&quot;malformed WriteBatch (too small)&quot;);</span><br><span class=\"line\">  }</span><br><span class=\"line\"></span><br><span class=\"line\">  input.remove_prefix(kHeader);</span><br><span class=\"line\">  Slice key, value;</span><br><span class=\"line\">  int found = 0;</span><br><span class=\"line\">  while (!input.empty()) {</span><br><span class=\"line\">    found++;</span><br><span class=\"line\">    char tag = input[0];</span><br><span class=\"line\">    input.remove_prefix(1);</span><br><span class=\"line\">    switch (tag) {</span><br><span class=\"line\">      case kTypeValue:</span><br><span class=\"line\">        if (GetLengthPrefixedSlice(&amp;input, &amp;key) &amp;&amp;</span><br><span class=\"line\">            GetLengthPrefixedSlice(&amp;input, &amp;value)) {</span><br><span class=\"line\">          handler-&gt;Put(key, value);</span><br><span class=\"line\">        } else {</span><br><span class=\"line\">          return Status::Corruption(&quot;bad WriteBatch Put&quot;);</span><br><span class=\"line\">        }</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      case kTypeDeletion:</span><br><span class=\"line\">        if (GetLengthPrefixedSlice(&amp;input, &amp;key)) {</span><br><span class=\"line\">          handler-&gt;Delete(key);</span><br><span class=\"line\">        } else {</span><br><span class=\"line\">          return Status::Corruption(&quot;bad WriteBatch Delete&quot;);</span><br><span class=\"line\">        }</span><br><span class=\"line\">        break;</span><br><span class=\"line\">      default:</span><br><span class=\"line\">        return Status::Corruption(&quot;unknown WriteBatch tag&quot;);</span><br><span class=\"line\">    }</span><br><span class=\"line\">  }</span><br><span class=\"line\">  if (found != WriteBatchInternal::Count(this)) {</span><br><span class=\"line\">    return Status::Corruption(&quot;WriteBatch has wrong count&quot;);</span><br><span class=\"line\">  } else {</span><br><span class=\"line\">    return Status::OK();</span><br><span class=\"line\">  }</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure><p></p>\n<h3 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h3><p>Hoo, finally get here! This article mainly talks about how batch operation is handled in leveldb. Due to space limitation, other import parts like WAL and Memtable in leveldb cannot be presented here.</p>\n<p>Have fun<del>~</del></p>\n</body></html>","site":{"data":{}},"_categories":[{"name":"Technology","path":"categories/Technology/"}],"_tags":[{"name":"database","path":"tags/database/"},{"name":"leveldb","path":"tags/leveldb/"}],"excerpt":"<html><head></head><body><h3 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h3><p>As a well-known key-value database,<a href=\"https://github.com/google/leveldb\" target=\"_blank\" rel=\"noopener\"> leveldb</a> provides general key-values interfaces like Put, Get and Delete. Besides those interfaces, leveldb provides a batch operation called WriteBatch as well. A batch operation means we can group multiple operations into one and submit this one to leveldb, the atomicity guarantees that either all of those operations are applied or none of them is applied.</p>\n<p>For example, we can use batch operation in leveldb in the following way:</p>\n<p><epacse hidden>0</epacse></p>\n<p>The updates are applied in the order in which they are added to the WriteBatch. And the value of &#x201C;key&#x201D; in the above code sample will be &#x201C;v3&#x201D; after the batch is written.</p>\n<h3 id=\"Implementaion-of-WriteBatch\"><a href=\"#Implementaion-of-WriteBatch\" class=\"headerlink\" title=\"Implementaion of WriteBatch\"></a>Implementaion of WriteBatch</h3><p>Well, how does leveldb implement this simple but powerful interface? Let&#x2019;s figure it out by digging the source code step by step.</p></body></html>","more":"<h4 id=\"WriteBatch-Class\"><a href=\"#WriteBatch-Class\" class=\"headerlink\" title=\"WriteBatch Class\"></a>WriteBatch Class</h4><p>The <code>WriteBatch</code> is a class containing member function <code>WriteBatch::Put</code>, <code>WriteBatch::Delete</code>,<code>WriteBatch::Clear</code> and <code>WriteBatch::Iterate</code>. A private member variable of string type called <code>rep_</code> is also owned by it.</p>\n<p>In the constructor of <code>WriteBatch</code>, <code>rep_</code> is cleared firstly and resize to length <code>kHeader</code>:</p>\n<p><epacse hidden>1</epacse></p>\n<p>That’s because the first <code>kHeader</code> bytes in <code>rep_</code> is used to maintain meta information: 8-byte sequence number and followed by a 4-byte count.</p>\n<p>Each time when the user calls <code>WriteBatch::Put</code>, the <code>rep_</code> variable gets updated by the following behaviors :</p>\n<p><epacse hidden>2</epacse></p>\n<p>Consequently, the 4-byte count in <code>rep_</code> gets incremented, and an enum char value <code>kTypeValue</code>(means this is a put operation), the key and the value are appended into the end of <code>rep_</code>.</p>\n<p>Similarly, when the user calls <code>WriteBatch::Delete</code>, the <code>rep_</code> variable is updated in a similar way:</p>\n<p><epacse hidden>3</epacse></p>\n<p>Excepting that an enum char value <code>kTypeDeletion</code>(means this is a put operation) and the key information are appended into the <code>rep_</code>.</p>\n<p>Let’s be more specific about the function <code>PutLengthPrefixedSlice</code> called by both <code>WriteBatch::Delete</code>and <code>WriteBatch::Put</code>:</p>\n<p><epacse hidden>4</epacse></p>\n<p>It appends the value size into dst and then the value itself into dst.</p>\n<p>Based on all the information provided above, we know that the <code>Put</code> and <code>Delete</code> member function of <code>WriteBatch</code> only update its member variable <code>rep_</code>. </p>\n<p>And we can also know the data layout format of <code>rep_</code>: </p>\n<p><epacse hidden>5</epacse></p>\n<img src=\"/2020/05/16/The-mechanism-behind-WriteBatch-in-leveldb/rep_format.png\" class=\"\" title=\"image of rep_ format\">\n\n\n\n<h4 id=\"DBImpl-Write\"><a href=\"#DBImpl-Write\" class=\"headerlink\" title=\"DBImpl::Write\"></a>DBImpl::Write</h4><p>After a batch operation is encapsulated, it’s time to call <code>DBImpl::Write</code> to apply the batch operation into the underlying layer to persist it.</p>\n<p>Inside <code>DBImpl::Write</code>, an instance of <code>Writer</code> called <code>w</code> , which represents the batch operation context, is created and added to the end of the double-ended queue <code>writers_</code>.  Because write operation is in strict order, so the write thread must wait until <code>w</code> is the first element of <code>writers_</code>.</p>\n<p><epacse hidden>6</epacse></p>\n<p>When the condition is fulfilled, leveldb will make sure there is enough room for this batch operation. Enough room mainly means memtable is prepared well to handle this write (I will write another new article to talk about that). Because <code>w</code> becomes the first element in <code>writers_</code>, the write thread will try to group other writers behind <code>w</code> into a so-called <code>BatchGroup</code> to speed up the io efficiency by the function <code>DBImpl::BuildBatchGroup</code>.</p>\n<p><epacse hidden>7</epacse></p>\n<p>Inside <code>DBImpl::BuildBatchGroup</code>, it will traverse the whole <code>writers_</code> from beginning to end and try to group all  those batches into one batch. For convenience to clarify, we call this procedure “batch mergence”</p>\n<p>However, there are some limitations in batch mergence. First, the maximum size of <code>rep_</code> in the merged batch group is <strong>1M</strong> and if the first writer is a small writer(<code>rep_.size() &lt;= 128K</code> ) it will limit the maximum size to <code>rep_.size() + 128K</code>. The idea behind this is not slowing down the small write too much. Second, it will not include a sync write into the batch handled by a non-sync write.</p>\n<p>In the batch mergence, with the help of <code>WriteBatchInternal::Append</code>, the data field of <code>rep_</code> in second batch is appended to the end of the <code>rep_</code> in first batch:</p>\n<p><epacse hidden>8</epacse></p>\n<p>After batch mergence is finished, a new batch called <code>updates</code> is generated. And the sequence number in <code>rep_</code> of <code>updates</code> is set to <code>last_sequence + 1</code>, <code>last_sequnce</code> gets adjusted to a new one(<code>last_sequnce = last_sequnce + count field rep_ of updates</code>) as well.</p>\n<p>Now, we come to the IO critical path. The WAL in leveldb will persist the contents of the <code>update</code> in an append-only way. After that success, memtable will replay the operations in the batch <code>update</code> and do corresponding behavior in memtable:</p>\n<p>Apply to WAL and insert into memtable:</p>\n<p><epacse hidden>9</epacse></p>\n<p><code>WriteBatch</code> Parse the whole <code>rep_</code> string to replay original operations specified by users and call handler(MemTableInserter) to handle these operations.</p>\n<p><epacse hidden>10</epacse></p>\n<h3 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h3><p>Hoo, finally get here! This article mainly talks about how batch operation is handled in leveldb. Due to space limitation, other import parts like WAL and Memtable in leveldb cannot be presented here.</p>\n<p>Have fun<del>~</del></p>"},{"title":"Redo log in InnoDB","date":"2016-07-09T09:33:15.000Z","_content":"\n## What is redo log\n\nFor a relational database, ACID is a set of properties that it must support for a transaction. That is to say, a transaction should be atomic, consistent, isolated and durable under the management of such database.\nInnoDB, the default storage engine since MySQL 5.5, use a method called **redo log** to implement the durability of a transaction. Redo log consists of redo log buffer and redo log file.\nThe redo log buffer resides in memory and is volatile while the redo log file resides in disks and is durable. Redo log records the information about a transaction. As the literal meaning of words redo log denotes, you can redo your operations after the system crashes by redo log.\n\n<!-- more -->\n\n## How does it work\n\nAs a transaction-based storage engine, InnoDB uses “force log at commit” mechanism to achieve durability.\nSo before a transaction is committed, all logs of that transaction must be flushed to redo log files. Even though the whole system crashes during the process of transaction commit, this transaction can be recovered by the redo log file after the system boots up again.\nThere exist a redo log memory buffer where the redo log is written to boost system performance. To ensure that redo log is written to redo log file successfully each time, the InnoDB storage engine need to call the `fsync` because `O_DIRECT` flag is not used when open redo log so that redo log is written to file system buffer firstly. Nevertheless, the time consumed by `fsync` call is up to the performance of disk. Consequently, the performance of disk determines the performance of transaction commit.[Reference1](http://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html)\n\nTaking account of the performance problem mentioned previously, the InnoDB storage engine allows user to set up the frequency of calling `fsync`. Specifically, parameter `innodb_flush_log_at_trx_commit` is used for frequency management. `innodb_flush_log_at_trx_commit` controls the balance between strict ACID compliance for commit operations, and higher performance that is possible when commit-related I/O operations are rearranged and done in batches. You can achieve better performance by changing the default value, but then you can lose up to a second of transactions in a crash.\n\n- The default value of 1 is required for full ACID compliance. With this value, the contents of the InnoDB log buffer are written out to the log file at each transaction commit and the log file is flushed to disk.\n- With a value of 0, the contents of the InnoDB log buffer are written to the log file approximately once per second and the log file is flushed to disk. No writes from the log buffer to the log file are performed at transaction commit. Once-per-second flushing is not 100% guaranteed to happen every second, due to process scheduling issues. Because the flush to disk operation only occurs approximately once per second, you can lose up to a second of transactions with any mysqld process crash\n- With a value of 2, the contents of the InnoDB log buffer are written to the log file after each transaction commit and the log file is flushed to disk approximately once per second. Once-per-second flushing is not 100% guaranteed to happen every second, due to process scheduling issues. Because the flush to disk operation only occurs approximately once per second, you can lose up to a second of transactions in an operating system crash or a power outage.[Reference2](https://book.douban.com/subject/25872763/)\n\n## The format of redo log file\n\nIn InnoDB storage engine, the redo logs are stored in 512-byte format. This means that redo log cache, redo log files are both kept in blocks and each bock has a size of 512 bytes. Besides the log itself in block, log block header and lock block tailer are also stored in each block. In a redo log block, 12 bytes and 8 bytes are occupied by redo log header and redo log tailer respectively(So real information stored in each block is 492 bytes).\n{% asset_img redo-log-block.jpg image of redo log file %}\n","source":"_posts/Redo-log-in-InnoDB.md","raw":"---\ntitle: Redo log in InnoDB\ndate: 2016-07-09 17:33:15\ntags: [database, mysql]\ncategories: Technology\n---\n\n## What is redo log\n\nFor a relational database, ACID is a set of properties that it must support for a transaction. That is to say, a transaction should be atomic, consistent, isolated and durable under the management of such database.\nInnoDB, the default storage engine since MySQL 5.5, use a method called **redo log** to implement the durability of a transaction. Redo log consists of redo log buffer and redo log file.\nThe redo log buffer resides in memory and is volatile while the redo log file resides in disks and is durable. Redo log records the information about a transaction. As the literal meaning of words redo log denotes, you can redo your operations after the system crashes by redo log.\n\n<!-- more -->\n\n## How does it work\n\nAs a transaction-based storage engine, InnoDB uses “force log at commit” mechanism to achieve durability.\nSo before a transaction is committed, all logs of that transaction must be flushed to redo log files. Even though the whole system crashes during the process of transaction commit, this transaction can be recovered by the redo log file after the system boots up again.\nThere exist a redo log memory buffer where the redo log is written to boost system performance. To ensure that redo log is written to redo log file successfully each time, the InnoDB storage engine need to call the `fsync` because `O_DIRECT` flag is not used when open redo log so that redo log is written to file system buffer firstly. Nevertheless, the time consumed by `fsync` call is up to the performance of disk. Consequently, the performance of disk determines the performance of transaction commit.[Reference1](http://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html)\n\nTaking account of the performance problem mentioned previously, the InnoDB storage engine allows user to set up the frequency of calling `fsync`. Specifically, parameter `innodb_flush_log_at_trx_commit` is used for frequency management. `innodb_flush_log_at_trx_commit` controls the balance between strict ACID compliance for commit operations, and higher performance that is possible when commit-related I/O operations are rearranged and done in batches. You can achieve better performance by changing the default value, but then you can lose up to a second of transactions in a crash.\n\n- The default value of 1 is required for full ACID compliance. With this value, the contents of the InnoDB log buffer are written out to the log file at each transaction commit and the log file is flushed to disk.\n- With a value of 0, the contents of the InnoDB log buffer are written to the log file approximately once per second and the log file is flushed to disk. No writes from the log buffer to the log file are performed at transaction commit. Once-per-second flushing is not 100% guaranteed to happen every second, due to process scheduling issues. Because the flush to disk operation only occurs approximately once per second, you can lose up to a second of transactions with any mysqld process crash\n- With a value of 2, the contents of the InnoDB log buffer are written to the log file after each transaction commit and the log file is flushed to disk approximately once per second. Once-per-second flushing is not 100% guaranteed to happen every second, due to process scheduling issues. Because the flush to disk operation only occurs approximately once per second, you can lose up to a second of transactions in an operating system crash or a power outage.[Reference2](https://book.douban.com/subject/25872763/)\n\n## The format of redo log file\n\nIn InnoDB storage engine, the redo logs are stored in 512-byte format. This means that redo log cache, redo log files are both kept in blocks and each bock has a size of 512 bytes. Besides the log itself in block, log block header and lock block tailer are also stored in each block. In a redo log block, 12 bytes and 8 bytes are occupied by redo log header and redo log tailer respectively(So real information stored in each block is 492 bytes).\n{% asset_img redo-log-block.jpg image of redo log file %}\n","slug":"Redo-log-in-InnoDB","published":1,"updated":"2020-05-16T14:15:14.110Z","_id":"cka9nungs0000acpk3popcxt3","comments":1,"layout":"post","photos":[],"link":"","content":"<html><head></head><body><h2 id=\"What-is-redo-log\"><a href=\"#What-is-redo-log\" class=\"headerlink\" title=\"What is redo log\"></a>What is redo log</h2><p>For a relational database, ACID is a set of properties that it must support for a transaction. That is to say, a transaction should be atomic, consistent, isolated and durable under the management of such database.<br>InnoDB, the default storage engine since MySQL 5.5, use a method called <strong>redo log</strong> to implement the durability of a transaction. Redo log consists of redo log buffer and redo log file.<br>The redo log buffer resides in memory and is volatile while the redo log file resides in disks and is durable. Redo log records the information about a transaction. As the literal meaning of words redo log denotes, you can redo your operations after the system crashes by redo log.</p>\n<a id=\"more\"></a>\n\n<h2 id=\"How-does-it-work\"><a href=\"#How-does-it-work\" class=\"headerlink\" title=\"How does it work\"></a>How does it work</h2><p>As a transaction-based storage engine, InnoDB uses &#x201C;force log at commit&#x201D; mechanism to achieve durability.<br>So before a transaction is committed, all logs of that transaction must be flushed to redo log files. Even though the whole system crashes during the process of transaction commit, this transaction can be recovered by the redo log file after the system boots up again.<br>There exist a redo log memory buffer where the redo log is written to boost system performance. To ensure that redo log is written to redo log file successfully each time, the InnoDB storage engine need to call the <code>fsync</code> because <code>O_DIRECT</code> flag is not used when open redo log so that redo log is written to file system buffer firstly. Nevertheless, the time consumed by <code>fsync</code> call is up to the performance of disk. Consequently, the performance of disk determines the performance of transaction commit.<a href=\"http://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html\" target=\"_blank\" rel=\"noopener\">Reference1</a></p>\n<p>Taking account of the performance problem mentioned previously, the InnoDB storage engine allows user to set up the frequency of calling <code>fsync</code>. Specifically, parameter <code>innodb_flush_log_at_trx_commit</code> is used for frequency management. <code>innodb_flush_log_at_trx_commit</code> controls the balance between strict ACID compliance for commit operations, and higher performance that is possible when commit-related I/O operations are rearranged and done in batches. You can achieve better performance by changing the default value, but then you can lose up to a second of transactions in a crash.</p>\n<ul>\n<li>The default value of 1 is required for full ACID compliance. With this value, the contents of the InnoDB log buffer are written out to the log file at each transaction commit and the log file is flushed to disk.</li>\n<li>With a value of 0, the contents of the InnoDB log buffer are written to the log file approximately once per second and the log file is flushed to disk. No writes from the log buffer to the log file are performed at transaction commit. Once-per-second flushing is not 100% guaranteed to happen every second, due to process scheduling issues. Because the flush to disk operation only occurs approximately once per second, you can lose up to a second of transactions with any mysqld process crash</li>\n<li>With a value of 2, the contents of the InnoDB log buffer are written to the log file after each transaction commit and the log file is flushed to disk approximately once per second. Once-per-second flushing is not 100% guaranteed to happen every second, due to process scheduling issues. Because the flush to disk operation only occurs approximately once per second, you can lose up to a second of transactions in an operating system crash or a power outage.<a href=\"https://book.douban.com/subject/25872763/\" target=\"_blank\" rel=\"noopener\">Reference2</a></li>\n</ul>\n<h2 id=\"The-format-of-redo-log-file\"><a href=\"#The-format-of-redo-log-file\" class=\"headerlink\" title=\"The format of redo log file\"></a>The format of redo log file</h2><p>In InnoDB storage engine, the redo logs are stored in 512-byte format. This means that redo log cache, redo log files are both kept in blocks and each bock has a size of 512 bytes. Besides the log itself in block, log block header and lock block tailer are also stored in each block. In a redo log block, 12 bytes and 8 bytes are occupied by redo log header and redo log tailer respectively(So real information stored in each block is 492 bytes).</p>\n<img src=\"/2016/07/09/Redo-log-in-InnoDB/redo-log-block.jpg\" class title=\"image of redo log file\">\n</body></html>","site":{"data":{}},"_categories":[{"name":"Technology","path":"categories/Technology/"}],"_tags":[{"name":"database","path":"tags/database/"},{"name":"mysql","path":"tags/mysql/"}],"excerpt":"<html><head></head><body><h2 id=\"What-is-redo-log\"><a href=\"#What-is-redo-log\" class=\"headerlink\" title=\"What is redo log\"></a>What is redo log</h2><p>For a relational database, ACID is a set of properties that it must support for a transaction. That is to say, a transaction should be atomic, consistent, isolated and durable under the management of such database.<br>InnoDB, the default storage engine since MySQL 5.5, use a method called <strong>redo log</strong> to implement the durability of a transaction. Redo log consists of redo log buffer and redo log file.<br>The redo log buffer resides in memory and is volatile while the redo log file resides in disks and is durable. Redo log records the information about a transaction. As the literal meaning of words redo log denotes, you can redo your operations after the system crashes by redo log.</p></body></html>","more":"<h2 id=\"How-does-it-work\"><a href=\"#How-does-it-work\" class=\"headerlink\" title=\"How does it work\"></a>How does it work</h2><p>As a transaction-based storage engine, InnoDB uses “force log at commit” mechanism to achieve durability.<br>So before a transaction is committed, all logs of that transaction must be flushed to redo log files. Even though the whole system crashes during the process of transaction commit, this transaction can be recovered by the redo log file after the system boots up again.<br>There exist a redo log memory buffer where the redo log is written to boost system performance. To ensure that redo log is written to redo log file successfully each time, the InnoDB storage engine need to call the <code>fsync</code> because <code>O_DIRECT</code> flag is not used when open redo log so that redo log is written to file system buffer firstly. Nevertheless, the time consumed by <code>fsync</code> call is up to the performance of disk. Consequently, the performance of disk determines the performance of transaction commit.<a href=\"http://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html\" target=\"_blank\" rel=\"noopener\">Reference1</a></p>\n<p>Taking account of the performance problem mentioned previously, the InnoDB storage engine allows user to set up the frequency of calling <code>fsync</code>. Specifically, parameter <code>innodb_flush_log_at_trx_commit</code> is used for frequency management. <code>innodb_flush_log_at_trx_commit</code> controls the balance between strict ACID compliance for commit operations, and higher performance that is possible when commit-related I/O operations are rearranged and done in batches. You can achieve better performance by changing the default value, but then you can lose up to a second of transactions in a crash.</p>\n<ul>\n<li>The default value of 1 is required for full ACID compliance. With this value, the contents of the InnoDB log buffer are written out to the log file at each transaction commit and the log file is flushed to disk.</li>\n<li>With a value of 0, the contents of the InnoDB log buffer are written to the log file approximately once per second and the log file is flushed to disk. No writes from the log buffer to the log file are performed at transaction commit. Once-per-second flushing is not 100% guaranteed to happen every second, due to process scheduling issues. Because the flush to disk operation only occurs approximately once per second, you can lose up to a second of transactions with any mysqld process crash</li>\n<li>With a value of 2, the contents of the InnoDB log buffer are written to the log file after each transaction commit and the log file is flushed to disk approximately once per second. Once-per-second flushing is not 100% guaranteed to happen every second, due to process scheduling issues. Because the flush to disk operation only occurs approximately once per second, you can lose up to a second of transactions in an operating system crash or a power outage.<a href=\"https://book.douban.com/subject/25872763/\" target=\"_blank\" rel=\"noopener\">Reference2</a></li>\n</ul>\n<h2 id=\"The-format-of-redo-log-file\"><a href=\"#The-format-of-redo-log-file\" class=\"headerlink\" title=\"The format of redo log file\"></a>The format of redo log file</h2><p>In InnoDB storage engine, the redo logs are stored in 512-byte format. This means that redo log cache, redo log files are both kept in blocks and each bock has a size of 512 bytes. Besides the log itself in block, log block header and lock block tailer are also stored in each block. In a redo log block, 12 bytes and 8 bytes are occupied by redo log header and redo log tailer respectively(So real information stored in each block is 492 bytes).</p>\n<img src=\"/2016/07/09/Redo-log-in-InnoDB/redo-log-block.jpg\" class=\"\" title=\"image of redo log file\">"},{"title":"Compile your own linux kernel","date":"2016-03-23T06:33:15.000Z","_content":"\nAs we know, linux is one of the greatest open source projects in the world and serves millions of enterprises. An open source project means that you can define your own features catering to different application scenarios. All big Internet firms such as Google, Facebook and Aamazon recompile the linux kernel so that features can be added to or removed from the official kernel release version.\nCompiling the kernel for linux kernel developers is also unavoidable. In the rest part of this post, attention will focus on tutorials on compiling a linux kernel.\n\n\n\n### 1. Getting the kernel source of official release\n\nNothing comes from nothing. So the first thing before compiling a customized kernel is getting source code.\nI strongly recommend using `Git` to download and manage the linux kernel source:\n\n```\ngit clone source_git_link\n```\n\n<!-- more -->\n\n\nSurely, you can also download the compressed package of source code and then uncompress it.\nGo to the source code root directory, there exists a number of directories under it.\n\n{% asset_img kernel-directory.png kernel src file dir %}\n\nThe following table[1] illustrates explanation about these directories.\n\n|   Directory   |                  Description                  |\n| :-----------: | :-------------------------------------------: |\n|     arch      |         Architecture-specific source          |\n|     block     |                Block I/O layer                |\n|     certs     |             SSL/TLS certification             |\n|    crypto     |                  Crypto API                   |\n| Documentation |          Kernel source documentation          |\n|    drivers    |                drivers Device                 |\n|   firmware    | Device firmware needed to use certain drivers |\n|      fs       |    The VFS and the individual filesystems     |\n|    include    |                Kernel headers                 |\n|     init      |        Kernel boot and initialization         |\n|      ipc      |        Interprocess communication code        |\n|    kernel     |    Core subsystems, such as the scheduler     |\n|      lib      |                Helper routines                |\n|      mm       |    Memory management subsystem and the VM     |\n|      net      |             Networking subsystem              |\n|    samples    |          Sample, demonstrative code           |\n|    scripts    |       Scripts used to build the kernel        |\n|   security    |             Linux Security Module             |\n|     sound     |                Sound subsystem                |\n|      usr      |   Early user-space code (called initramfs)    |\n|     tools     |      Tools helpful for developing Linux       |\n|     virt      |         Virtualization infrastructure         |\n\n### 2. Building the kernel source code\n\nAfter the first step, you come here. Now what you should do is configuring the kernel before compiling. As mentioned previously, it is possible to compile support into your kernel for only the specific features and drivers you want. Configuring the kernel is a required process before building it. By default, the kernel of official release version provides myriad features and supports a varied basket of hardware.\n\n#### (1). Configuration\n\nwhen you change your current working directory to the root directory of linux kernel source code, you will find there is a file named **.config**. Using command such as `cat .config | more` you can take a glimpse of its content.\n\n```\ncat .config | more\n```\n\n{% asset_img kernel-configuration.png kernel config file %}\n\nAs shown in the picture, kernel configuration is controlled by configuration options, which are prefixed by **CONFIG** in the form **CONFIG_FEATURE**. That is to say, asynchronous IO is controlled by the configuration option **CONFIG_AIO**. This option enables POSIX asynchronous I/O which may by used by some high performance threaded applications[Reference][2]. When this option is set, AIO is enabled; if unset, AIO is disabled.\nConfiguration options that control the build process are either Booleans or tristates. A Boolean option is either yes or no. Kernel features, such as CONFIG_PREEMPT, are usually Booleans. A tristate option is one of yes, no, or module.The module setting represents a configuration option that is set but is to be compiled as a module (that is, a separate dynamically loadable object). In the case of tristates, a yes option explicitly means to compile the code into the main kernel image and not as a module. Drivers are usually represented by tristates[Reference][3].\nConfiguration options can also be strings or integers.These options do not control the build process but instead specify values that kernel source can access as a preprocessor macro. For example, a configuration option can specify the size of a statically allocated array[Reference][4].\nKernel provides multiple choices for you to facilitate configurations. A straightfoward way is using a graphical interactive interface: `make menuconfig`.\n\n```\nmake menuconfig\n```\n\nAfter typing this command, a graphical interactive interface will appears in your screen like this:\n\n{% asset_img kernel-menuconfig.png kernel menuconfig file %}\n\nAnd you can move the cursor to different options to set them. Because of space, how to configure these options correctly can not be presented. For more detailed knowledge, you can find them in the linux orgnization.\n\n#### (2). Compile and build\n\nNow, it is time to get into the marrow of the second part: Compile && Build. Please make sure that command `make` and `gcc` is installed on your machine firstly.\nJust type `make` and all related source code about kernel will be compiled and built, the default Makefile rule will handle everything.\n\n```\nmake\n```\n\nIn general, one flaw about the `make` method is that this action spawns only a single job because Makefiles all too often have incorrect dependency information. With incorrect dependencies, multiple jobs can step on each other’s toes, resulting in errors in the build process. However, The kernel’s Makefile have correct dependency information, so spawning multiple jobs does not result in failures. To build the kernel with multiple make jobs, use\n\n```\nmake -jn\n```\n\nThe n here is number of jobs to spawn. Usual practice is to spawn one or two jobs per processor. If you have 16 processors in you machine, then you might do\n\n```\nmake -j32\n```\n\nThe resulting kernel file is “arch/x86/boot/bzImage” (in x86 platform).\n\n### 3. Installation\n\nAfter the kernel is built, you can install it. It is possible that the kernel you install cannot boot successfully, so in case of that, you should have at least two kernel installed on you machine so that you can choose the another one to boot.\n\n#### (1). Install modules\n\nInstalling modules, thankfully, is automated and architecture-independent. As root, simply run\n\n```\nmake modules_install\n```\n\nAfter this, you will find a module file under **/lib/modules/a.b.c** where a.b.c is the kernel version.\n\n#### (2). Install kernel\n\nAs root user, simply run\n\n```\nmake install\n```\n\nAfter this, a new kernel file and a new boot image will appear in the **/boot** directory.\n\n#### (3). Set booting order\n\nIf you execute all the steps normally, new content about the new installed kernel has been added to **/boot/grub/grub.conf** file. And you can edit the **grub.conf** file to choose to use which kernel when booting.\n\n{% asset_img kernel-grub.png kernel grub file %}\n\nReboot the machine, and then you will find the new installed kernel in the booting screen.\n\n{% asset_img kernel-booting.png booting file %}\n\n[1]: Love, Robert Love. (2003). Linux Kernel Development, 3, 40-42\n\n[2]: http://cateee.net/lkddb/web-lkddb/AIO.html\n\n[3]: Love, Robert Love. (2003). Linux Kernel Development, 3, 42-43\n[4]: Love, Robert Love. (2003). Linux Kernel Development, 3, 43-45\n","source":"_posts/Compile-your-own-linux-kernel.md","raw":"---\ntitle: Compile your own linux kernel\ndate: 2016-03-23 14:33:15\ntags: [kernel, linux]\ncategories: Technology\n---\n\nAs we know, linux is one of the greatest open source projects in the world and serves millions of enterprises. An open source project means that you can define your own features catering to different application scenarios. All big Internet firms such as Google, Facebook and Aamazon recompile the linux kernel so that features can be added to or removed from the official kernel release version.\nCompiling the kernel for linux kernel developers is also unavoidable. In the rest part of this post, attention will focus on tutorials on compiling a linux kernel.\n\n\n\n### 1. Getting the kernel source of official release\n\nNothing comes from nothing. So the first thing before compiling a customized kernel is getting source code.\nI strongly recommend using `Git` to download and manage the linux kernel source:\n\n```\ngit clone source_git_link\n```\n\n<!-- more -->\n\n\nSurely, you can also download the compressed package of source code and then uncompress it.\nGo to the source code root directory, there exists a number of directories under it.\n\n{% asset_img kernel-directory.png kernel src file dir %}\n\nThe following table[1] illustrates explanation about these directories.\n\n|   Directory   |                  Description                  |\n| :-----------: | :-------------------------------------------: |\n|     arch      |         Architecture-specific source          |\n|     block     |                Block I/O layer                |\n|     certs     |             SSL/TLS certification             |\n|    crypto     |                  Crypto API                   |\n| Documentation |          Kernel source documentation          |\n|    drivers    |                drivers Device                 |\n|   firmware    | Device firmware needed to use certain drivers |\n|      fs       |    The VFS and the individual filesystems     |\n|    include    |                Kernel headers                 |\n|     init      |        Kernel boot and initialization         |\n|      ipc      |        Interprocess communication code        |\n|    kernel     |    Core subsystems, such as the scheduler     |\n|      lib      |                Helper routines                |\n|      mm       |    Memory management subsystem and the VM     |\n|      net      |             Networking subsystem              |\n|    samples    |          Sample, demonstrative code           |\n|    scripts    |       Scripts used to build the kernel        |\n|   security    |             Linux Security Module             |\n|     sound     |                Sound subsystem                |\n|      usr      |   Early user-space code (called initramfs)    |\n|     tools     |      Tools helpful for developing Linux       |\n|     virt      |         Virtualization infrastructure         |\n\n### 2. Building the kernel source code\n\nAfter the first step, you come here. Now what you should do is configuring the kernel before compiling. As mentioned previously, it is possible to compile support into your kernel for only the specific features and drivers you want. Configuring the kernel is a required process before building it. By default, the kernel of official release version provides myriad features and supports a varied basket of hardware.\n\n#### (1). Configuration\n\nwhen you change your current working directory to the root directory of linux kernel source code, you will find there is a file named **.config**. Using command such as `cat .config | more` you can take a glimpse of its content.\n\n```\ncat .config | more\n```\n\n{% asset_img kernel-configuration.png kernel config file %}\n\nAs shown in the picture, kernel configuration is controlled by configuration options, which are prefixed by **CONFIG** in the form **CONFIG_FEATURE**. That is to say, asynchronous IO is controlled by the configuration option **CONFIG_AIO**. This option enables POSIX asynchronous I/O which may by used by some high performance threaded applications[Reference][2]. When this option is set, AIO is enabled; if unset, AIO is disabled.\nConfiguration options that control the build process are either Booleans or tristates. A Boolean option is either yes or no. Kernel features, such as CONFIG_PREEMPT, are usually Booleans. A tristate option is one of yes, no, or module.The module setting represents a configuration option that is set but is to be compiled as a module (that is, a separate dynamically loadable object). In the case of tristates, a yes option explicitly means to compile the code into the main kernel image and not as a module. Drivers are usually represented by tristates[Reference][3].\nConfiguration options can also be strings or integers.These options do not control the build process but instead specify values that kernel source can access as a preprocessor macro. For example, a configuration option can specify the size of a statically allocated array[Reference][4].\nKernel provides multiple choices for you to facilitate configurations. A straightfoward way is using a graphical interactive interface: `make menuconfig`.\n\n```\nmake menuconfig\n```\n\nAfter typing this command, a graphical interactive interface will appears in your screen like this:\n\n{% asset_img kernel-menuconfig.png kernel menuconfig file %}\n\nAnd you can move the cursor to different options to set them. Because of space, how to configure these options correctly can not be presented. For more detailed knowledge, you can find them in the linux orgnization.\n\n#### (2). Compile and build\n\nNow, it is time to get into the marrow of the second part: Compile && Build. Please make sure that command `make` and `gcc` is installed on your machine firstly.\nJust type `make` and all related source code about kernel will be compiled and built, the default Makefile rule will handle everything.\n\n```\nmake\n```\n\nIn general, one flaw about the `make` method is that this action spawns only a single job because Makefiles all too often have incorrect dependency information. With incorrect dependencies, multiple jobs can step on each other’s toes, resulting in errors in the build process. However, The kernel’s Makefile have correct dependency information, so spawning multiple jobs does not result in failures. To build the kernel with multiple make jobs, use\n\n```\nmake -jn\n```\n\nThe n here is number of jobs to spawn. Usual practice is to spawn one or two jobs per processor. If you have 16 processors in you machine, then you might do\n\n```\nmake -j32\n```\n\nThe resulting kernel file is “arch/x86/boot/bzImage” (in x86 platform).\n\n### 3. Installation\n\nAfter the kernel is built, you can install it. It is possible that the kernel you install cannot boot successfully, so in case of that, you should have at least two kernel installed on you machine so that you can choose the another one to boot.\n\n#### (1). Install modules\n\nInstalling modules, thankfully, is automated and architecture-independent. As root, simply run\n\n```\nmake modules_install\n```\n\nAfter this, you will find a module file under **/lib/modules/a.b.c** where a.b.c is the kernel version.\n\n#### (2). Install kernel\n\nAs root user, simply run\n\n```\nmake install\n```\n\nAfter this, a new kernel file and a new boot image will appear in the **/boot** directory.\n\n#### (3). Set booting order\n\nIf you execute all the steps normally, new content about the new installed kernel has been added to **/boot/grub/grub.conf** file. And you can edit the **grub.conf** file to choose to use which kernel when booting.\n\n{% asset_img kernel-grub.png kernel grub file %}\n\nReboot the machine, and then you will find the new installed kernel in the booting screen.\n\n{% asset_img kernel-booting.png booting file %}\n\n[1]: Love, Robert Love. (2003). Linux Kernel Development, 3, 40-42\n\n[2]: http://cateee.net/lkddb/web-lkddb/AIO.html\n\n[3]: Love, Robert Love. (2003). Linux Kernel Development, 3, 42-43\n[4]: Love, Robert Love. (2003). Linux Kernel Development, 3, 43-45\n","slug":"Compile-your-own-linux-kernel","published":1,"updated":"2020-05-16T14:15:50.082Z","_id":"cka9oizps0000r6pkf8gta8e5","comments":1,"layout":"post","photos":[],"link":"","content":"<html><head></head><body><p>As we know, linux is one of the greatest open source projects in the world and serves millions of enterprises. An open source project means that you can define your own features catering to different application scenarios. All big Internet firms such as Google, Facebook and Aamazon recompile the linux kernel so that features can be added to or removed from the official kernel release version.<br>Compiling the kernel for linux kernel developers is also unavoidable. In the rest part of this post, attention will focus on tutorials on compiling a linux kernel.</p>\n<h3 id=\"1-Getting-the-kernel-source-of-official-release\"><a href=\"#1-Getting-the-kernel-source-of-official-release\" class=\"headerlink\" title=\"1. Getting the kernel source of official release\"></a>1. Getting the kernel source of official release</h3><p>Nothing comes from nothing. So the first thing before compiling a customized kernel is getting source code.<br>I strongly recommend using <code>Git</code> to download and manage the linux kernel source:</p>\n<p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone source_git_link</span><br></pre></td></tr></tbody></table></figure><p></p>\n<a id=\"more\"></a>\n\n\n<p>Surely, you can also download the compressed package of source code and then uncompress it.<br>Go to the source code root directory, there exists a number of directories under it.</p>\n<img src=\"/2016/03/23/Compile-your-own-linux-kernel/kernel-directory.png\" class title=\"kernel src file dir\">\n\n<p>The following table[1] illustrates explanation about these directories.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Directory</th>\n<th align=\"center\">Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">arch</td>\n<td align=\"center\">Architecture-specific source</td>\n</tr>\n<tr>\n<td align=\"center\">block</td>\n<td align=\"center\">Block I/O layer</td>\n</tr>\n<tr>\n<td align=\"center\">certs</td>\n<td align=\"center\">SSL/TLS certification</td>\n</tr>\n<tr>\n<td align=\"center\">crypto</td>\n<td align=\"center\">Crypto API</td>\n</tr>\n<tr>\n<td align=\"center\">Documentation</td>\n<td align=\"center\">Kernel source documentation</td>\n</tr>\n<tr>\n<td align=\"center\">drivers</td>\n<td align=\"center\">drivers Device</td>\n</tr>\n<tr>\n<td align=\"center\">firmware</td>\n<td align=\"center\">Device firmware needed to use certain drivers</td>\n</tr>\n<tr>\n<td align=\"center\">fs</td>\n<td align=\"center\">The VFS and the individual filesystems</td>\n</tr>\n<tr>\n<td align=\"center\">include</td>\n<td align=\"center\">Kernel headers</td>\n</tr>\n<tr>\n<td align=\"center\">init</td>\n<td align=\"center\">Kernel boot and initialization</td>\n</tr>\n<tr>\n<td align=\"center\">ipc</td>\n<td align=\"center\">Interprocess communication code</td>\n</tr>\n<tr>\n<td align=\"center\">kernel</td>\n<td align=\"center\">Core subsystems, such as the scheduler</td>\n</tr>\n<tr>\n<td align=\"center\">lib</td>\n<td align=\"center\">Helper routines</td>\n</tr>\n<tr>\n<td align=\"center\">mm</td>\n<td align=\"center\">Memory management subsystem and the VM</td>\n</tr>\n<tr>\n<td align=\"center\">net</td>\n<td align=\"center\">Networking subsystem</td>\n</tr>\n<tr>\n<td align=\"center\">samples</td>\n<td align=\"center\">Sample, demonstrative code</td>\n</tr>\n<tr>\n<td align=\"center\">scripts</td>\n<td align=\"center\">Scripts used to build the kernel</td>\n</tr>\n<tr>\n<td align=\"center\">security</td>\n<td align=\"center\">Linux Security Module</td>\n</tr>\n<tr>\n<td align=\"center\">sound</td>\n<td align=\"center\">Sound subsystem</td>\n</tr>\n<tr>\n<td align=\"center\">usr</td>\n<td align=\"center\">Early user-space code (called initramfs)</td>\n</tr>\n<tr>\n<td align=\"center\">tools</td>\n<td align=\"center\">Tools helpful for developing Linux</td>\n</tr>\n<tr>\n<td align=\"center\">virt</td>\n<td align=\"center\">Virtualization infrastructure</td>\n</tr>\n</tbody></table>\n<h3 id=\"2-Building-the-kernel-source-code\"><a href=\"#2-Building-the-kernel-source-code\" class=\"headerlink\" title=\"2. Building the kernel source code\"></a>2. Building the kernel source code</h3><p>After the first step, you come here. Now what you should do is configuring the kernel before compiling. As mentioned previously, it is possible to compile support into your kernel for only the specific features and drivers you want. Configuring the kernel is a required process before building it. By default, the kernel of official release version provides myriad features and supports a varied basket of hardware.</p>\n<h4 id=\"1-Configuration\"><a href=\"#1-Configuration\" class=\"headerlink\" title=\"(1). Configuration\"></a>(1). Configuration</h4><p>when you change your current working directory to the root directory of linux kernel source code, you will find there is a file named <strong>.config</strong>. Using command such as <code>cat .config | more</code> you can take a glimpse of its content.</p>\n<p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat .config | more</span><br></pre></td></tr></tbody></table></figure><p></p>\n<img src=\"/2016/03/23/Compile-your-own-linux-kernel/kernel-configuration.png\" class title=\"kernel config file\">\n\n<p>As shown in the picture, kernel configuration is controlled by configuration options, which are prefixed by <strong>CONFIG</strong> in the form <strong>CONFIG_FEATURE</strong>. That is to say, asynchronous IO is controlled by the configuration option <strong>CONFIG_AIO</strong>. This option enables POSIX asynchronous I/O which may by used by some high performance threaded applications<a href=\"http://cateee.net/lkddb/web-lkddb/AIO.html\" target=\"_blank\" rel=\"noopener\">Reference</a>. When this option is set, AIO is enabled; if unset, AIO is disabled.<br>Configuration options that control the build process are either Booleans or tristates. A Boolean option is either yes or no. Kernel features, such as CONFIG_PREEMPT, are usually Booleans. A tristate option is one of yes, no, or module.The module setting represents a configuration option that is set but is to be compiled as a module (that is, a separate dynamically loadable object). In the case of tristates, a yes option explicitly means to compile the code into the main kernel image and not as a module. Drivers are usually represented by tristates[Reference][3].<br>Configuration options can also be strings or integers.These options do not control the build process but instead specify values that kernel source can access as a preprocessor macro. For example, a configuration option can specify the size of a statically allocated array[Reference][4].<br>Kernel provides multiple choices for you to facilitate configurations. A straightfoward way is using a graphical interactive interface: <code>make menuconfig</code>.</p>\n<p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make menuconfig</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>After typing this command, a graphical interactive interface will appears in your screen like this:</p>\n<img src=\"/2016/03/23/Compile-your-own-linux-kernel/kernel-menuconfig.png\" class title=\"kernel menuconfig file\">\n\n<p>And you can move the cursor to different options to set them. Because of space, how to configure these options correctly can not be presented. For more detailed knowledge, you can find them in the linux orgnization.</p>\n<h4 id=\"2-Compile-and-build\"><a href=\"#2-Compile-and-build\" class=\"headerlink\" title=\"(2). Compile and build\"></a>(2). Compile and build</h4><p>Now, it is time to get into the marrow of the second part: Compile &amp;&amp; Build. Please make sure that command <code>make</code> and <code>gcc</code> is installed on your machine firstly.<br>Just type <code>make</code> and all related source code about kernel will be compiled and built, the default Makefile rule will handle everything.</p>\n<p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>In general, one flaw about the <code>make</code> method is that this action spawns only a single job because Makefiles all too often have incorrect dependency information. With incorrect dependencies, multiple jobs can step on each other&#x2019;s toes, resulting in errors in the build process. However, The kernel&#x2019;s Makefile have correct dependency information, so spawning multiple jobs does not result in failures. To build the kernel with multiple make jobs, use</p>\n<p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make -jn</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>The n here is number of jobs to spawn. Usual practice is to spawn one or two jobs per processor. If you have 16 processors in you machine, then you might do</p>\n<p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make -j32</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>The resulting kernel file is &#x201C;arch/x86/boot/bzImage&#x201D; (in x86 platform).</p>\n<h3 id=\"3-Installation\"><a href=\"#3-Installation\" class=\"headerlink\" title=\"3. Installation\"></a>3. Installation</h3><p>After the kernel is built, you can install it. It is possible that the kernel you install cannot boot successfully, so in case of that, you should have at least two kernel installed on you machine so that you can choose the another one to boot.</p>\n<h4 id=\"1-Install-modules\"><a href=\"#1-Install-modules\" class=\"headerlink\" title=\"(1). Install modules\"></a>(1). Install modules</h4><p>Installing modules, thankfully, is automated and architecture-independent. As root, simply run</p>\n<p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make modules_install</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>After this, you will find a module file under <strong>/lib/modules/a.b.c</strong> where a.b.c is the kernel version.</p>\n<h4 id=\"2-Install-kernel\"><a href=\"#2-Install-kernel\" class=\"headerlink\" title=\"(2). Install kernel\"></a>(2). Install kernel</h4><p>As root user, simply run</p>\n<p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make install</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>After this, a new kernel file and a new boot image will appear in the <strong>/boot</strong> directory.</p>\n<h4 id=\"3-Set-booting-order\"><a href=\"#3-Set-booting-order\" class=\"headerlink\" title=\"(3). Set booting order\"></a>(3). Set booting order</h4><p>If you execute all the steps normally, new content about the new installed kernel has been added to <strong>/boot/grub/grub.conf</strong> file. And you can edit the <strong>grub.conf</strong> file to choose to use which kernel when booting.</p>\n<img src=\"/2016/03/23/Compile-your-own-linux-kernel/kernel-grub.png\" class title=\"kernel grub file\">\n\n<p>Reboot the machine, and then you will find the new installed kernel in the booting screen.</p>\n<img src=\"/2016/03/23/Compile-your-own-linux-kernel/kernel-booting.png\" class title=\"booting file\">\n\n<p>[1]: Love, Robert Love. (2003). Linux Kernel Development, 3, 40-42</p>\n<p>[3]: Love, Robert Love. (2003). Linux Kernel Development, 3, 42-43<br>[4]: Love, Robert Love. (2003). Linux Kernel Development, 3, 43-45</p>\n</body></html>","site":{"data":{}},"_categories":[{"name":"Technology","path":"categories/Technology/"}],"_tags":[{"name":"kernel","path":"tags/kernel/"},{"name":"linux","path":"tags/linux/"}],"excerpt":"<html><head></head><body><p>As we know, linux is one of the greatest open source projects in the world and serves millions of enterprises. An open source project means that you can define your own features catering to different application scenarios. All big Internet firms such as Google, Facebook and Aamazon recompile the linux kernel so that features can be added to or removed from the official kernel release version.<br>Compiling the kernel for linux kernel developers is also unavoidable. In the rest part of this post, attention will focus on tutorials on compiling a linux kernel.</p>\n<h3 id=\"1-Getting-the-kernel-source-of-official-release\"><a href=\"#1-Getting-the-kernel-source-of-official-release\" class=\"headerlink\" title=\"1. Getting the kernel source of official release\"></a>1. Getting the kernel source of official release</h3><p>Nothing comes from nothing. So the first thing before compiling a customized kernel is getting source code.<br>I strongly recommend using <code>Git</code> to download and manage the linux kernel source:</p>\n<p><epacse hidden>11</epacse></p></body></html>","more":"<p>Surely, you can also download the compressed package of source code and then uncompress it.<br>Go to the source code root directory, there exists a number of directories under it.</p>\n<img src=\"/2016/03/23/Compile-your-own-linux-kernel/kernel-directory.png\" class=\"\" title=\"kernel src file dir\">\n\n<p>The following table[1] illustrates explanation about these directories.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Directory</th>\n<th align=\"center\">Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">arch</td>\n<td align=\"center\">Architecture-specific source</td>\n</tr>\n<tr>\n<td align=\"center\">block</td>\n<td align=\"center\">Block I/O layer</td>\n</tr>\n<tr>\n<td align=\"center\">certs</td>\n<td align=\"center\">SSL/TLS certification</td>\n</tr>\n<tr>\n<td align=\"center\">crypto</td>\n<td align=\"center\">Crypto API</td>\n</tr>\n<tr>\n<td align=\"center\">Documentation</td>\n<td align=\"center\">Kernel source documentation</td>\n</tr>\n<tr>\n<td align=\"center\">drivers</td>\n<td align=\"center\">drivers Device</td>\n</tr>\n<tr>\n<td align=\"center\">firmware</td>\n<td align=\"center\">Device firmware needed to use certain drivers</td>\n</tr>\n<tr>\n<td align=\"center\">fs</td>\n<td align=\"center\">The VFS and the individual filesystems</td>\n</tr>\n<tr>\n<td align=\"center\">include</td>\n<td align=\"center\">Kernel headers</td>\n</tr>\n<tr>\n<td align=\"center\">init</td>\n<td align=\"center\">Kernel boot and initialization</td>\n</tr>\n<tr>\n<td align=\"center\">ipc</td>\n<td align=\"center\">Interprocess communication code</td>\n</tr>\n<tr>\n<td align=\"center\">kernel</td>\n<td align=\"center\">Core subsystems, such as the scheduler</td>\n</tr>\n<tr>\n<td align=\"center\">lib</td>\n<td align=\"center\">Helper routines</td>\n</tr>\n<tr>\n<td align=\"center\">mm</td>\n<td align=\"center\">Memory management subsystem and the VM</td>\n</tr>\n<tr>\n<td align=\"center\">net</td>\n<td align=\"center\">Networking subsystem</td>\n</tr>\n<tr>\n<td align=\"center\">samples</td>\n<td align=\"center\">Sample, demonstrative code</td>\n</tr>\n<tr>\n<td align=\"center\">scripts</td>\n<td align=\"center\">Scripts used to build the kernel</td>\n</tr>\n<tr>\n<td align=\"center\">security</td>\n<td align=\"center\">Linux Security Module</td>\n</tr>\n<tr>\n<td align=\"center\">sound</td>\n<td align=\"center\">Sound subsystem</td>\n</tr>\n<tr>\n<td align=\"center\">usr</td>\n<td align=\"center\">Early user-space code (called initramfs)</td>\n</tr>\n<tr>\n<td align=\"center\">tools</td>\n<td align=\"center\">Tools helpful for developing Linux</td>\n</tr>\n<tr>\n<td align=\"center\">virt</td>\n<td align=\"center\">Virtualization infrastructure</td>\n</tr>\n</tbody></table>\n<h3 id=\"2-Building-the-kernel-source-code\"><a href=\"#2-Building-the-kernel-source-code\" class=\"headerlink\" title=\"2. Building the kernel source code\"></a>2. Building the kernel source code</h3><p>After the first step, you come here. Now what you should do is configuring the kernel before compiling. As mentioned previously, it is possible to compile support into your kernel for only the specific features and drivers you want. Configuring the kernel is a required process before building it. By default, the kernel of official release version provides myriad features and supports a varied basket of hardware.</p>\n<h4 id=\"1-Configuration\"><a href=\"#1-Configuration\" class=\"headerlink\" title=\"(1). Configuration\"></a>(1). Configuration</h4><p>when you change your current working directory to the root directory of linux kernel source code, you will find there is a file named <strong>.config</strong>. Using command such as <code>cat .config | more</code> you can take a glimpse of its content.</p>\n<p><epacse hidden>12</epacse></p>\n<img src=\"/2016/03/23/Compile-your-own-linux-kernel/kernel-configuration.png\" class=\"\" title=\"kernel config file\">\n\n<p>As shown in the picture, kernel configuration is controlled by configuration options, which are prefixed by <strong>CONFIG</strong> in the form <strong>CONFIG_FEATURE</strong>. That is to say, asynchronous IO is controlled by the configuration option <strong>CONFIG_AIO</strong>. This option enables POSIX asynchronous I/O which may by used by some high performance threaded applications<a href=\"http://cateee.net/lkddb/web-lkddb/AIO.html\" target=\"_blank\" rel=\"noopener\">Reference</a>. When this option is set, AIO is enabled; if unset, AIO is disabled.<br>Configuration options that control the build process are either Booleans or tristates. A Boolean option is either yes or no. Kernel features, such as CONFIG_PREEMPT, are usually Booleans. A tristate option is one of yes, no, or module.The module setting represents a configuration option that is set but is to be compiled as a module (that is, a separate dynamically loadable object). In the case of tristates, a yes option explicitly means to compile the code into the main kernel image and not as a module. Drivers are usually represented by tristates[Reference][3].<br>Configuration options can also be strings or integers.These options do not control the build process but instead specify values that kernel source can access as a preprocessor macro. For example, a configuration option can specify the size of a statically allocated array[Reference][4].<br>Kernel provides multiple choices for you to facilitate configurations. A straightfoward way is using a graphical interactive interface: <code>make menuconfig</code>.</p>\n<p><epacse hidden>13</epacse></p>\n<p>After typing this command, a graphical interactive interface will appears in your screen like this:</p>\n<img src=\"/2016/03/23/Compile-your-own-linux-kernel/kernel-menuconfig.png\" class=\"\" title=\"kernel menuconfig file\">\n\n<p>And you can move the cursor to different options to set them. Because of space, how to configure these options correctly can not be presented. For more detailed knowledge, you can find them in the linux orgnization.</p>\n<h4 id=\"2-Compile-and-build\"><a href=\"#2-Compile-and-build\" class=\"headerlink\" title=\"(2). Compile and build\"></a>(2). Compile and build</h4><p>Now, it is time to get into the marrow of the second part: Compile &amp;&amp; Build. Please make sure that command <code>make</code> and <code>gcc</code> is installed on your machine firstly.<br>Just type <code>make</code> and all related source code about kernel will be compiled and built, the default Makefile rule will handle everything.</p>\n<p><epacse hidden>14</epacse></p>\n<p>In general, one flaw about the <code>make</code> method is that this action spawns only a single job because Makefiles all too often have incorrect dependency information. With incorrect dependencies, multiple jobs can step on each other’s toes, resulting in errors in the build process. However, The kernel’s Makefile have correct dependency information, so spawning multiple jobs does not result in failures. To build the kernel with multiple make jobs, use</p>\n<p><epacse hidden>15</epacse></p>\n<p>The n here is number of jobs to spawn. Usual practice is to spawn one or two jobs per processor. If you have 16 processors in you machine, then you might do</p>\n<p><epacse hidden>16</epacse></p>\n<p>The resulting kernel file is “arch/x86/boot/bzImage” (in x86 platform).</p>\n<h3 id=\"3-Installation\"><a href=\"#3-Installation\" class=\"headerlink\" title=\"3. Installation\"></a>3. Installation</h3><p>After the kernel is built, you can install it. It is possible that the kernel you install cannot boot successfully, so in case of that, you should have at least two kernel installed on you machine so that you can choose the another one to boot.</p>\n<h4 id=\"1-Install-modules\"><a href=\"#1-Install-modules\" class=\"headerlink\" title=\"(1). Install modules\"></a>(1). Install modules</h4><p>Installing modules, thankfully, is automated and architecture-independent. As root, simply run</p>\n<p><epacse hidden>17</epacse></p>\n<p>After this, you will find a module file under <strong>/lib/modules/a.b.c</strong> where a.b.c is the kernel version.</p>\n<h4 id=\"2-Install-kernel\"><a href=\"#2-Install-kernel\" class=\"headerlink\" title=\"(2). Install kernel\"></a>(2). Install kernel</h4><p>As root user, simply run</p>\n<p><epacse hidden>18</epacse></p>\n<p>After this, a new kernel file and a new boot image will appear in the <strong>/boot</strong> directory.</p>\n<h4 id=\"3-Set-booting-order\"><a href=\"#3-Set-booting-order\" class=\"headerlink\" title=\"(3). Set booting order\"></a>(3). Set booting order</h4><p>If you execute all the steps normally, new content about the new installed kernel has been added to <strong>/boot/grub/grub.conf</strong> file. And you can edit the <strong>grub.conf</strong> file to choose to use which kernel when booting.</p>\n<img src=\"/2016/03/23/Compile-your-own-linux-kernel/kernel-grub.png\" class=\"\" title=\"kernel grub file\">\n\n<p>Reboot the machine, and then you will find the new installed kernel in the booting screen.</p>\n<img src=\"/2016/03/23/Compile-your-own-linux-kernel/kernel-booting.png\" class=\"\" title=\"booting file\">\n\n<p>[1]: Love, Robert Love. (2003). Linux Kernel Development, 3, 40-42</p>\n<p>[3]: Love, Robert Love. (2003). Linux Kernel Development, 3, 42-43<br>[4]: Love, Robert Love. (2003). Linux Kernel Development, 3, 43-45</p>"},{"title":"Read and Write functions in linux","date":"2016-04-12T13:43:21.000Z","_content":"\nResulting from work, I have learned I/O models of the linux operating system during these days. In linux operating system, various read and write APIs are provided to user space for use. Comparasions between them are illustraed below.\n\n\n\n### read()\n\n```\n#include <unistd.h>\nssize_t read(int fd, void *buf, size_t count);\n```\n\n`read()` is the basic read function in linux environment. It attempts to read up to count bytes from file descriptor fd into the buffer starting at buf.\nIt will start from current file offset. And the current file offset will be increased by the number of bytes read. However, if current file offset is at or past the end of operating file, no bytes will be read into buffer.\nOn success, the number of bytes read is returned (zero indicates end of file), and the file position is advanced by this number. It is not an error if this number is smaller than the number of bytes requested; this may happen for example because fewer bytes are actually available right now (maybe because we were close to end-of-file, or because we are reading from a pipe, or from a terminal), or because `read()` was interrupted by a signal. On error, -1 is returned, and errno is set appropriately. In this case it is left unspecified whether the file position (if any) changes.[Reference](http://linux.die.net/man/2/read)\n`read()` is thread safe in the sense that your program will not have undefined behavior (crash or hung) if multiple threads perform IO on the same open file using at once. But the order and atomicity of these operations could vary greatly depending on the type of the file and the implementation of program.\n\n\n<!-- more -->\n\n### lseek()\n\n```\n#include <sys/types.h>\n#include <unistd.h>\noff_t lseek(int fd, off_t offset, int whence);\n```\n\nThe `lseek()` function repositions the offset of the open file associated with the file descriptor fd to the argument offset according to the directive whence\nThe directive whence can be as follows:\n**SEEK_SET** The offset is set to offset bytes.\n**SEEK_CUR** The offset is set to its current location plus offset bytes.\n**SEEK_END** The offset is set to the size of the file plus offset bytes.\nWhen whence is as the last one, `lseek()` function allows the file offset to be set beyond the size of file while the file size still keeps the same. If data is latter write at this point, subsequent reads of the data in the gap (as a “hole”) return null bytes until data is actually written to this gap. [Reference](http://linux.die.net/man/2/lseek)\nThere are some special usage methods about `lseek()`:\n\n1. `lseek(int fildes, 0, SEEK_SET)`:\n   move the read or write position to the start of the file\n2. `lseek(int fildes, 0, SEEK_END)`:\n   move the read or write position to the end of the file\n3. `lseek(int fildes, 0, SEEK_CUR)`:\n   get the current read or write position of the file\n\nWith `lseek()`, you can implement the random I/O models of read and write easily.\n\n### pread()\n\n```\n#include <unistd.h>\nssize_t pread(int fd, void *buf, size_t count, off_t offset);\n```\n\nSimilar to `read()`, `pread()` attempts to read count bytes from file descriptor fd at offset into buffer starting at buf. Unlike `read()`, the offset here will be not changed after the call of `pread`\nIn many cases `pread()` is the only option when you’re dealing with threads reading from a database or such.\nCompared with `read()`, `pread()` does more than `read()` on account of the time to positioning offset. From the work mechanism of `pread()`, we can find that it is like the combination of `read()` and `lseek()`. Nevertheless, performance of `pread()` is quite higher than the combination of `read()` and `lseek()`.\nAs mentioned above, `read()` function will be in mess when multiple threads or processes perform IO operations on the same open file because it will increase the current file offset. On the flip side, `pread()` do not change the position in the open file so it is more convenient to using in the scenario of multiple threads and processes.\n\n### pwrite()\n\n```\n#include <unistd.h>\nssize_t pwrite(int fd, const void *buf, size_t nbytes, off_t offset);\n\t\t\t\tReturns: number of bytes written if OK, −1 on error\n```\n\nCalling `pwrite()` is equivalent to calling `lseek()` followed by a call to `write()`. Instead of calling `lseesk()` and `write()` separately, the combination of `lseek()` and `write()` is atomic operation in `pwrite()`.\n","source":"_posts/Read-and-Write-functions-in-linux.md","raw":"---\ntitle: Read and Write functions in linux\ndate: 2016-04-12 21:43:21\ntags: [linux, C]\ncategories: Technology\n---\n\nResulting from work, I have learned I/O models of the linux operating system during these days. In linux operating system, various read and write APIs are provided to user space for use. Comparasions between them are illustraed below.\n\n\n\n### read()\n\n```\n#include <unistd.h>\nssize_t read(int fd, void *buf, size_t count);\n```\n\n`read()` is the basic read function in linux environment. It attempts to read up to count bytes from file descriptor fd into the buffer starting at buf.\nIt will start from current file offset. And the current file offset will be increased by the number of bytes read. However, if current file offset is at or past the end of operating file, no bytes will be read into buffer.\nOn success, the number of bytes read is returned (zero indicates end of file), and the file position is advanced by this number. It is not an error if this number is smaller than the number of bytes requested; this may happen for example because fewer bytes are actually available right now (maybe because we were close to end-of-file, or because we are reading from a pipe, or from a terminal), or because `read()` was interrupted by a signal. On error, -1 is returned, and errno is set appropriately. In this case it is left unspecified whether the file position (if any) changes.[Reference](http://linux.die.net/man/2/read)\n`read()` is thread safe in the sense that your program will not have undefined behavior (crash or hung) if multiple threads perform IO on the same open file using at once. But the order and atomicity of these operations could vary greatly depending on the type of the file and the implementation of program.\n\n\n<!-- more -->\n\n### lseek()\n\n```\n#include <sys/types.h>\n#include <unistd.h>\noff_t lseek(int fd, off_t offset, int whence);\n```\n\nThe `lseek()` function repositions the offset of the open file associated with the file descriptor fd to the argument offset according to the directive whence\nThe directive whence can be as follows:\n**SEEK_SET** The offset is set to offset bytes.\n**SEEK_CUR** The offset is set to its current location plus offset bytes.\n**SEEK_END** The offset is set to the size of the file plus offset bytes.\nWhen whence is as the last one, `lseek()` function allows the file offset to be set beyond the size of file while the file size still keeps the same. If data is latter write at this point, subsequent reads of the data in the gap (as a “hole”) return null bytes until data is actually written to this gap. [Reference](http://linux.die.net/man/2/lseek)\nThere are some special usage methods about `lseek()`:\n\n1. `lseek(int fildes, 0, SEEK_SET)`:\n   move the read or write position to the start of the file\n2. `lseek(int fildes, 0, SEEK_END)`:\n   move the read or write position to the end of the file\n3. `lseek(int fildes, 0, SEEK_CUR)`:\n   get the current read or write position of the file\n\nWith `lseek()`, you can implement the random I/O models of read and write easily.\n\n### pread()\n\n```\n#include <unistd.h>\nssize_t pread(int fd, void *buf, size_t count, off_t offset);\n```\n\nSimilar to `read()`, `pread()` attempts to read count bytes from file descriptor fd at offset into buffer starting at buf. Unlike `read()`, the offset here will be not changed after the call of `pread`\nIn many cases `pread()` is the only option when you’re dealing with threads reading from a database or such.\nCompared with `read()`, `pread()` does more than `read()` on account of the time to positioning offset. From the work mechanism of `pread()`, we can find that it is like the combination of `read()` and `lseek()`. Nevertheless, performance of `pread()` is quite higher than the combination of `read()` and `lseek()`.\nAs mentioned above, `read()` function will be in mess when multiple threads or processes perform IO operations on the same open file because it will increase the current file offset. On the flip side, `pread()` do not change the position in the open file so it is more convenient to using in the scenario of multiple threads and processes.\n\n### pwrite()\n\n```\n#include <unistd.h>\nssize_t pwrite(int fd, const void *buf, size_t nbytes, off_t offset);\n\t\t\t\tReturns: number of bytes written if OK, −1 on error\n```\n\nCalling `pwrite()` is equivalent to calling `lseek()` followed by a call to `write()`. Instead of calling `lseesk()` and `write()` separately, the combination of `lseek()` and `write()` is atomic operation in `pwrite()`.\n","slug":"Read-and-Write-functions-in-linux","published":1,"updated":"2020-05-16T14:16:06.995Z","_id":"cka9on2a8000011pk5h00g8jk","comments":1,"layout":"post","photos":[],"link":"","content":"<html><head></head><body><p>Resulting from work, I have learned I/O models of the linux operating system during these days. In linux operating system, various read and write APIs are provided to user space for use. Comparasions between them are illustraed below.</p>\n<h3 id=\"read\"><a href=\"#read\" class=\"headerlink\" title=\"read()\"></a>read()</h3><p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;unistd.h&gt;</span><br><span class=\"line\">ssize_t read(int fd, void *buf, size_t count);</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p><code>read()</code> is the basic read function in linux environment. It attempts to read up to count bytes from file descriptor fd into the buffer starting at buf.<br>It will start from current file offset. And the current file offset will be increased by the number of bytes read. However, if current file offset is at or past the end of operating file, no bytes will be read into buffer.<br>On success, the number of bytes read is returned (zero indicates end of file), and the file position is advanced by this number. It is not an error if this number is smaller than the number of bytes requested; this may happen for example because fewer bytes are actually available right now (maybe because we were close to end-of-file, or because we are reading from a pipe, or from a terminal), or because <code>read()</code> was interrupted by a signal. On error, -1 is returned, and errno is set appropriately. In this case it is left unspecified whether the file position (if any) changes.<a href=\"http://linux.die.net/man/2/read\" target=\"_blank\" rel=\"noopener\">Reference</a><br><code>read()</code> is thread safe in the sense that your program will not have undefined behavior (crash or hung) if multiple threads perform IO on the same open file using at once. But the order and atomicity of these operations could vary greatly depending on the type of the file and the implementation of program.</p>\n<a id=\"more\"></a>\n\n<h3 id=\"lseek\"><a href=\"#lseek\" class=\"headerlink\" title=\"lseek()\"></a>lseek()</h3><p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;sys/types.h&gt;</span><br><span class=\"line\">#include &lt;unistd.h&gt;</span><br><span class=\"line\">off_t lseek(int fd, off_t offset, int whence);</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>The <code>lseek()</code> function repositions the offset of the open file associated with the file descriptor fd to the argument offset according to the directive whence<br>The directive whence can be as follows:<br><strong>SEEK_SET</strong> The offset is set to offset bytes.<br><strong>SEEK_CUR</strong> The offset is set to its current location plus offset bytes.<br><strong>SEEK_END</strong> The offset is set to the size of the file plus offset bytes.<br>When whence is as the last one, <code>lseek()</code> function allows the file offset to be set beyond the size of file while the file size still keeps the same. If data is latter write at this point, subsequent reads of the data in the gap (as a &#x201C;hole&#x201D;) return null bytes until data is actually written to this gap. <a href=\"http://linux.die.net/man/2/lseek\" target=\"_blank\" rel=\"noopener\">Reference</a><br>There are some special usage methods about <code>lseek()</code>:</p>\n<ol>\n<li><code>lseek(int fildes, 0, SEEK_SET)</code>:<br>move the read or write position to the start of the file</li>\n<li><code>lseek(int fildes, 0, SEEK_END)</code>:<br>move the read or write position to the end of the file</li>\n<li><code>lseek(int fildes, 0, SEEK_CUR)</code>:<br>get the current read or write position of the file</li>\n</ol>\n<p>With <code>lseek()</code>, you can implement the random I/O models of read and write easily.</p>\n<h3 id=\"pread\"><a href=\"#pread\" class=\"headerlink\" title=\"pread()\"></a>pread()</h3><p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;unistd.h&gt;</span><br><span class=\"line\">ssize_t pread(int fd, void *buf, size_t count, off_t offset);</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>Similar to <code>read()</code>, <code>pread()</code> attempts to read count bytes from file descriptor fd at offset into buffer starting at buf. Unlike <code>read()</code>, the offset here will be not changed after the call of <code>pread</code><br>In many cases <code>pread()</code> is the only option when you&#x2019;re dealing with threads reading from a database or such.<br>Compared with <code>read()</code>, <code>pread()</code> does more than <code>read()</code> on account of the time to positioning offset. From the work mechanism of <code>pread()</code>, we can find that it is like the combination of <code>read()</code> and <code>lseek()</code>. Nevertheless, performance of <code>pread()</code> is quite higher than the combination of <code>read()</code> and <code>lseek()</code>.<br>As mentioned above, <code>read()</code> function will be in mess when multiple threads or processes perform IO operations on the same open file because it will increase the current file offset. On the flip side, <code>pread()</code> do not change the position in the open file so it is more convenient to using in the scenario of multiple threads and processes.</p>\n<h3 id=\"pwrite\"><a href=\"#pwrite\" class=\"headerlink\" title=\"pwrite()\"></a>pwrite()</h3><p></p><figure class=\"highlight plain hljs\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;unistd.h&gt;</span><br><span class=\"line\">ssize_t pwrite(int fd, const void *buf, size_t nbytes, off_t offset);</span><br><span class=\"line\">\t\t\t\tReturns: number of bytes written if OK, &#x2212;1 on error</span><br></pre></td></tr></tbody></table></figure><p></p>\n<p>Calling <code>pwrite()</code> is equivalent to calling <code>lseek()</code> followed by a call to <code>write()</code>. Instead of calling <code>lseesk()</code> and <code>write()</code> separately, the combination of <code>lseek()</code> and <code>write()</code> is atomic operation in <code>pwrite()</code>.</p>\n</body></html>","site":{"data":{}},"_categories":[{"name":"Technology","path":"categories/Technology/"}],"_tags":[{"name":"linux","path":"tags/linux/"},{"name":"C","path":"tags/C/"}],"excerpt":"<html><head></head><body><p>Resulting from work, I have learned I/O models of the linux operating system during these days. In linux operating system, various read and write APIs are provided to user space for use. Comparasions between them are illustraed below.</p>\n<h3 id=\"read\"><a href=\"#read\" class=\"headerlink\" title=\"read()\"></a>read()</h3><p><epacse hidden>19</epacse></p>\n<p><code>read()</code> is the basic read function in linux environment. It attempts to read up to count bytes from file descriptor fd into the buffer starting at buf.<br>It will start from current file offset. And the current file offset will be increased by the number of bytes read. However, if current file offset is at or past the end of operating file, no bytes will be read into buffer.<br>On success, the number of bytes read is returned (zero indicates end of file), and the file position is advanced by this number. It is not an error if this number is smaller than the number of bytes requested; this may happen for example because fewer bytes are actually available right now (maybe because we were close to end-of-file, or because we are reading from a pipe, or from a terminal), or because <code>read()</code> was interrupted by a signal. On error, -1 is returned, and errno is set appropriately. In this case it is left unspecified whether the file position (if any) changes.<a href=\"http://linux.die.net/man/2/read\" target=\"_blank\" rel=\"noopener\">Reference</a><br><code>read()</code> is thread safe in the sense that your program will not have undefined behavior (crash or hung) if multiple threads perform IO on the same open file using at once. But the order and atomicity of these operations could vary greatly depending on the type of the file and the implementation of program.</p></body></html>","more":"<h3 id=\"lseek\"><a href=\"#lseek\" class=\"headerlink\" title=\"lseek()\"></a>lseek()</h3><p><epacse hidden>20</epacse></p>\n<p>The <code>lseek()</code> function repositions the offset of the open file associated with the file descriptor fd to the argument offset according to the directive whence<br>The directive whence can be as follows:<br><strong>SEEK_SET</strong> The offset is set to offset bytes.<br><strong>SEEK_CUR</strong> The offset is set to its current location plus offset bytes.<br><strong>SEEK_END</strong> The offset is set to the size of the file plus offset bytes.<br>When whence is as the last one, <code>lseek()</code> function allows the file offset to be set beyond the size of file while the file size still keeps the same. If data is latter write at this point, subsequent reads of the data in the gap (as a “hole”) return null bytes until data is actually written to this gap. <a href=\"http://linux.die.net/man/2/lseek\" target=\"_blank\" rel=\"noopener\">Reference</a><br>There are some special usage methods about <code>lseek()</code>:</p>\n<ol>\n<li><code>lseek(int fildes, 0, SEEK_SET)</code>:<br>move the read or write position to the start of the file</li>\n<li><code>lseek(int fildes, 0, SEEK_END)</code>:<br>move the read or write position to the end of the file</li>\n<li><code>lseek(int fildes, 0, SEEK_CUR)</code>:<br>get the current read or write position of the file</li>\n</ol>\n<p>With <code>lseek()</code>, you can implement the random I/O models of read and write easily.</p>\n<h3 id=\"pread\"><a href=\"#pread\" class=\"headerlink\" title=\"pread()\"></a>pread()</h3><p><epacse hidden>21</epacse></p>\n<p>Similar to <code>read()</code>, <code>pread()</code> attempts to read count bytes from file descriptor fd at offset into buffer starting at buf. Unlike <code>read()</code>, the offset here will be not changed after the call of <code>pread</code><br>In many cases <code>pread()</code> is the only option when you’re dealing with threads reading from a database or such.<br>Compared with <code>read()</code>, <code>pread()</code> does more than <code>read()</code> on account of the time to positioning offset. From the work mechanism of <code>pread()</code>, we can find that it is like the combination of <code>read()</code> and <code>lseek()</code>. Nevertheless, performance of <code>pread()</code> is quite higher than the combination of <code>read()</code> and <code>lseek()</code>.<br>As mentioned above, <code>read()</code> function will be in mess when multiple threads or processes perform IO operations on the same open file because it will increase the current file offset. On the flip side, <code>pread()</code> do not change the position in the open file so it is more convenient to using in the scenario of multiple threads and processes.</p>\n<h3 id=\"pwrite\"><a href=\"#pwrite\" class=\"headerlink\" title=\"pwrite()\"></a>pwrite()</h3><p><epacse hidden>22</epacse></p>\n<p>Calling <code>pwrite()</code> is equivalent to calling <code>lseek()</code> followed by a call to <code>write()</code>. Instead of calling <code>lseesk()</code> and <code>write()</code> separately, the combination of <code>lseek()</code> and <code>write()</code> is atomic operation in <code>pwrite()</code>.</p>"}],"PostAsset":[{"_id":"source/_posts/The-mechanism-behind-WriteBatch-in-leveldb/rep_format.png","slug":"rep_format.png","post":"cka9n1t1y0000grpkegovf6kg","modified":0,"renderable":0},{"_id":"source/_posts/Redo-log-in-InnoDB/redo-log-block.jpg","slug":"redo-log-block.jpg","post":"cka9nungs0000acpk3popcxt3","modified":0,"renderable":0},{"_id":"source/_posts/Compile-your-own-linux-kernel/kernel-configuration.png","slug":"kernel-configuration.png","post":"cka9oizps0000r6pkf8gta8e5","modified":0,"renderable":0},{"_id":"source/_posts/Compile-your-own-linux-kernel/kernel-grub.png","slug":"kernel-grub.png","post":"cka9oizps0000r6pkf8gta8e5","modified":0,"renderable":0},{"_id":"source/_posts/Compile-your-own-linux-kernel/kernel-menuconfig.png","slug":"kernel-menuconfig.png","post":"cka9oizps0000r6pkf8gta8e5","modified":0,"renderable":0},{"_id":"source/_posts/Compile-your-own-linux-kernel/kernel-booting.png","slug":"kernel-booting.png","post":"cka9oizps0000r6pkf8gta8e5","modified":0,"renderable":0},{"_id":"source/_posts/Compile-your-own-linux-kernel/kernel-directory.png","slug":"kernel-directory.png","post":"cka9oizps0000r6pkf8gta8e5","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cka9oizps0000r6pkf8gta8e5","category_id":"cka9pgaji0000rppkhq8jbvzn","_id":"cka9pgajq0007rppkd1cgfoy9"},{"post_id":"cka9nungs0000acpk3popcxt3","category_id":"cka9pgaji0000rppkhq8jbvzn","_id":"cka9pgajq0009rppk0mjqf05i"},{"post_id":"cka9on2a8000011pk5h00g8jk","category_id":"cka9pgaji0000rppkhq8jbvzn","_id":"cka9pgajr000arppk6g72cyy4"},{"post_id":"cka9n1t1y0000grpkegovf6kg","category_id":"cka9pgaji0000rppkhq8jbvzn","_id":"cka9pgajt000brppk2sj87n3x"}],"PostTag":[{"post_id":"cka9n1t1y0000grpkegovf6kg","tag_id":"cka9n1t240001grpk5iy44al9","_id":"cka9n1t260002grpkhg2z4m16"},{"post_id":"cka9nungs0000acpk3popcxt3","tag_id":"cka9n1t240001grpk5iy44al9","_id":"cka9pgajn0002rppkdtllcrno"},{"post_id":"cka9oizps0000r6pkf8gta8e5","tag_id":"cka9oizpz0001r6pkgqv7cv3q","_id":"cka9pk8ip0000zvpk40tz920e"},{"post_id":"cka9on2a8000011pk5h00g8jk","tag_id":"cka9on2ae000111pk95bl1b6t","_id":"cka9pk8ir0003zvpk0l3n7ma6"},{"post_id":"cka9nungs0000acpk3popcxt3","tag_id":"cka9pqa290000dtpkgprd2bwu","_id":"cka9pqa2c0001dtpk90qweom1"},{"post_id":"cka9oizps0000r6pkf8gta8e5","tag_id":"cka9on2ae000111pk95bl1b6t","_id":"cka9ps08b0000iopk4d6z2fqo"},{"post_id":"cka9n1t1y0000grpkegovf6kg","tag_id":"cka9ps08d0001iopkbk4mbwsq","_id":"cka9ps08f0002iopkdi2y14gb"},{"post_id":"cka9on2a8000011pk5h00g8jk","tag_id":"cka9pk8ip0001zvpk745cai2w","_id":"cka9ps08j0003iopkhrly7zlq"}],"Tag":[{"name":"database","_id":"cka9n1t240001grpk5iy44al9"},{"name":"kernel","_id":"cka9oizpz0001r6pkgqv7cv3q"},{"name":"linux","_id":"cka9on2ae000111pk95bl1b6t"},{"name":"kernel, linux","_id":"cka9pgajl0001rppk0sgp35e1"},{"name":"linux, C","_id":"cka9pgajo0004rppkcp7rau1g"},{"name":"C","_id":"cka9pk8ip0001zvpk745cai2w"},{"name":"mysql","_id":"cka9pqa290000dtpkgprd2bwu"},{"name":"leveldb","_id":"cka9ps08d0001iopkbk4mbwsq"}]}}